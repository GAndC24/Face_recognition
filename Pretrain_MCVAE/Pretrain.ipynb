{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-24T03:20:12.928514Z",
     "start_time": "2025-01-24T03:20:09.593279Z"
    }
   },
   "source": [
    "from HP_optimizer_MCVGAN import HP_optimizer_MCVGAN\n",
    "import torch\n",
    "from Trainer_MCVGAN import Trainer_MCVGAN\n",
    "from Model_MCVGAN import Masked_ConViT_GAN_Generator, Masked_ConViT_GAN_Discriminator\n",
    "\n",
    "# 超参数\n",
    "img_size = 128\n",
    "NP = 60\n",
    "G = 10\n",
    "select_ratio = 0.8\n",
    "L = 18\n",
    "Pc = 0.8\n",
    "Pm = 0.05\n",
    "train_mini_epochs = 15\n",
    "epochs = 1000"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T06:46:22.919968Z",
     "start_time": "2025-01-24T03:20:13.025925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 初始化 Hyperparameter optimizer\n",
    "HP_optimizer = HP_optimizer_MCVGAN(img_size=img_size, NP=NP, select_ratio=select_ratio, G=G, L=L,\n",
    "                                       Pc=Pc, Pm=Pm, train_mini_epochs=train_mini_epochs)\n",
    "\n",
    "# 获取 best Hyperparameters\n",
    "HP_best = HP_optimizer.get_best_hyperparameters()"
   ],
   "id": "e7dba4d2b6dfde16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index: 1\n",
      "img_size : 128\n",
      "lr : 0.00022050703627575656\n",
      "weight_decay : 0.0006014644458417716\n",
      "warmup_proportion : 0.005163557723316963\n",
      "batch_size : 16\n",
      "embed_dim : 1024\n",
      "depth : 23\n",
      "num_heads : 8\n",
      "mlp_ratio : 4.0\n",
      "drop_rate : 0.3\n",
      "attn_drop_rate : 0.2\n",
      "drop_path_rate : 0.3\n",
      "local_up_to_layer : 8\n",
      "locality_strength : 0.5\n",
      "decoder_embed_dim : 768\n",
      "decoder_depth : 4\n",
      "decoder_num_heads : 8\n",
      "filter_size : 5\n",
      "num_filters : 32\n",
      "\n",
      "Epoch: 1, Step: 1, G Loss: 3.8219, D Loss: 1.3873, mask loss: 3.2083, extra loss: 1.2272\n",
      "Epoch: 1, Step: 2, G Loss: 3.2527, D Loss: 1.3873, mask loss: 2.7832, extra loss: 0.9391\n",
      "Epoch: 1, Step: 3, G Loss: 3.1227, D Loss: 1.3873, mask loss: 2.7652, extra loss: 0.7150\n",
      "Epoch: 1, Step: 4, G Loss: 3.0504, D Loss: 1.3873, mask loss: 2.7439, extra loss: 0.6131\n",
      "Epoch: 1, Step: 5, G Loss: 2.7196, D Loss: 1.3873, mask loss: 2.3899, extra loss: 0.6594\n",
      "Epoch: 1, Step: 6, G Loss: 2.6842, D Loss: 1.3873, mask loss: 2.3496, extra loss: 0.6693\n",
      "Epoch: 1, Step: 7, G Loss: 2.8632, D Loss: 1.3873, mask loss: 2.5968, extra loss: 0.5328\n",
      "Epoch: 1, Step: 8, G Loss: 2.7324, D Loss: 1.3873, mask loss: 2.4524, extra loss: 0.5599\n",
      "Epoch: 1, Step: 9, G Loss: 2.5487, D Loss: 1.3873, mask loss: 2.2751, extra loss: 0.5473\n",
      "Epoch: 1, Step: 10, G Loss: 2.5969, D Loss: 1.3873, mask loss: 2.3020, extra loss: 0.5897\n",
      "Epoch: 1, Step: 11, G Loss: 2.9951, D Loss: 1.0649, mask loss: 1.9609, extra loss: 2.0684\n",
      "Epoch: 1, Step: 12, G Loss: 3.2704, D Loss: 1.0649, mask loss: 2.2924, extra loss: 1.9559\n",
      "Epoch: 1, Step: 13, G Loss: 2.9334, D Loss: 1.0649, mask loss: 1.9529, extra loss: 1.9610\n",
      "Epoch: 1, Step: 14, G Loss: 2.8540, D Loss: 1.0649, mask loss: 1.9195, extra loss: 1.8690\n",
      "Epoch: 1, Step: 15, G Loss: 2.9181, D Loss: 1.0649, mask loss: 1.9962, extra loss: 1.8437\n",
      "Epoch: 1, Step: 16, G Loss: 3.1727, D Loss: 1.0649, mask loss: 2.3885, extra loss: 1.5683\n",
      "Epoch: 1, Step: 17, G Loss: 2.9384, D Loss: 1.0649, mask loss: 2.1540, extra loss: 1.5688\n",
      "Epoch: 1, Step: 18, G Loss: 2.9285, D Loss: 1.0649, mask loss: 2.1336, extra loss: 1.5898\n",
      "Epoch: 1, Step: 19, G Loss: 2.9159, D Loss: 1.0649, mask loss: 2.1893, extra loss: 1.4532\n",
      "Epoch: 1, Step: 20, G Loss: 2.9055, D Loss: 1.0649, mask loss: 2.1899, extra loss: 1.4313\n",
      "Epoch: 1, Step: 21, G Loss: 3.6174, D Loss: 0.7548, mask loss: 2.1343, extra loss: 2.9662\n",
      "Epoch: 1, Step: 22, G Loss: 3.4164, D Loss: 0.7548, mask loss: 2.0483, extra loss: 2.7362\n",
      "Epoch: 1, Step: 23, G Loss: 3.7257, D Loss: 0.7548, mask loss: 2.4952, extra loss: 2.4611\n",
      "Epoch: 1, Step: 24, G Loss: 3.3231, D Loss: 0.7548, mask loss: 2.0996, extra loss: 2.4470\n",
      "Epoch: 1, Step: 25, G Loss: 3.2670, D Loss: 0.7548, mask loss: 2.1648, extra loss: 2.2044\n",
      "Epoch: 1, Step: 26, G Loss: 3.0920, D Loss: 0.7548, mask loss: 1.9684, extra loss: 2.2471\n",
      "Epoch: 1, Step: 27, G Loss: 3.0276, D Loss: 0.7548, mask loss: 2.0518, extra loss: 1.9516\n",
      "Epoch: 1, Step: 28, G Loss: 3.0696, D Loss: 0.7548, mask loss: 2.1623, extra loss: 1.8145\n",
      "Epoch: 1, Step: 29, G Loss: 2.8388, D Loss: 0.7548, mask loss: 2.0877, extra loss: 1.5022\n",
      "Epoch: 1, Step: 30, G Loss: 2.7778, D Loss: 0.7548, mask loss: 2.1056, extra loss: 1.3445\n",
      "Epoch: 1, Step: 31, G Loss: 3.5666, D Loss: 0.9499, mask loss: 2.1665, extra loss: 2.8002\n",
      "Epoch: 1, Step: 32, G Loss: 3.4762, D Loss: 0.9499, mask loss: 2.1586, extra loss: 2.6352\n",
      "Epoch: 1, Step: 33, G Loss: 3.0785, D Loss: 0.9499, mask loss: 1.9973, extra loss: 2.1623\n",
      "Epoch: 1, Step: 34, G Loss: 3.3494, D Loss: 0.9499, mask loss: 2.3737, extra loss: 1.9513\n",
      "Epoch: 1, Step: 35, G Loss: 2.8727, D Loss: 0.9499, mask loss: 2.1336, extra loss: 1.4782\n",
      "Epoch: 1, Step: 36, G Loss: 2.6365, D Loss: 0.9499, mask loss: 2.0604, extra loss: 1.1522\n",
      "Epoch: 1, Step: 37, G Loss: 2.7256, D Loss: 0.9499, mask loss: 2.2502, extra loss: 0.9508\n",
      "Epoch: 1, Step: 38, G Loss: 2.4222, D Loss: 0.9499, mask loss: 2.1085, extra loss: 0.6276\n",
      "Epoch: 1, Step: 39, G Loss: 2.5106, D Loss: 0.9499, mask loss: 2.2025, extra loss: 0.6162\n",
      "Epoch: 1, Step: 40, G Loss: 2.4886, D Loss: 0.9499, mask loss: 2.3512, extra loss: 0.2749\n",
      "Epoch: 1, Step: 41, G Loss: 3.6408, D Loss: 2.3884, mask loss: 2.1310, extra loss: 3.0196\n",
      "Epoch: 1, Step: 42, G Loss: 3.2146, D Loss: 2.3884, mask loss: 1.9541, extra loss: 2.5209\n",
      "Epoch: 1, Step: 43, G Loss: 3.1573, D Loss: 2.3884, mask loss: 2.2680, extra loss: 1.7786\n",
      "Epoch: 1, Step: 44, G Loss: 3.2567, D Loss: 2.3884, mask loss: 2.2449, extra loss: 2.0235\n",
      "Epoch: 1, Step: 45, G Loss: 2.7453, D Loss: 2.3884, mask loss: 2.1088, extra loss: 1.2732\n",
      "Epoch: 1, Step: 46, G Loss: 2.4932, D Loss: 2.3884, mask loss: 2.0203, extra loss: 0.9459\n",
      "Epoch: 1, Step: 47, G Loss: 2.6872, D Loss: 2.3884, mask loss: 2.3480, extra loss: 0.6784\n",
      "Epoch: 1, Step: 48, G Loss: 2.0961, D Loss: 2.3884, mask loss: 1.8101, extra loss: 0.5719\n",
      "Epoch: 1, Step: 49, G Loss: 2.2514, D Loss: 2.3884, mask loss: 2.0483, extra loss: 0.4062\n",
      "Epoch: 1, Step: 50, G Loss: 2.3840, D Loss: 2.3884, mask loss: 2.2084, extra loss: 0.3512\n",
      "Epoch: 1, Step: 51, G Loss: 4.1236, D Loss: 2.6954, mask loss: 2.4197, extra loss: 3.4078\n",
      "Epoch: 1, Step: 52, G Loss: 3.5509, D Loss: 2.6954, mask loss: 2.0713, extra loss: 2.9593\n",
      "Epoch: 1, Step: 53, G Loss: 3.4158, D Loss: 2.6954, mask loss: 2.0648, extra loss: 2.7020\n",
      "Epoch: 1, Step: 54, G Loss: 3.3204, D Loss: 2.6954, mask loss: 2.2883, extra loss: 2.0642\n",
      "Epoch: 1, Step: 55, G Loss: 2.8775, D Loss: 2.6954, mask loss: 2.0596, extra loss: 1.6358\n",
      "Epoch: 1, Step: 56, G Loss: 2.6920, D Loss: 2.6954, mask loss: 1.9600, extra loss: 1.4640\n",
      "Epoch: 1, Step: 57, G Loss: 2.3321, D Loss: 2.6954, mask loss: 1.9756, extra loss: 0.7130\n",
      "Epoch: 1, Step: 58, G Loss: 2.6474, D Loss: 2.6954, mask loss: 2.2853, extra loss: 0.7242\n",
      "Epoch: 1, Step: 59, G Loss: 2.2988, D Loss: 2.6954, mask loss: 2.0713, extra loss: 0.4550\n",
      "Epoch: 1, Step: 60, G Loss: 2.0753, D Loss: 2.6954, mask loss: 1.8898, extra loss: 0.3709\n",
      "Epoch: 1, Step: 61, G Loss: 4.0251, D Loss: 2.9137, mask loss: 2.2164, extra loss: 3.6173\n",
      "Epoch: 1, Step: 62, G Loss: 3.9199, D Loss: 2.9137, mask loss: 2.0441, extra loss: 3.7515\n",
      "Epoch: 1, Step: 63, G Loss: 3.6036, D Loss: 2.9137, mask loss: 1.9702, extra loss: 3.2667\n",
      "Epoch: 1, Step: 64, G Loss: 3.4692, D Loss: 2.9137, mask loss: 2.0211, extra loss: 2.8961\n",
      "Epoch: 1, Step: 65, G Loss: 2.9874, D Loss: 2.9137, mask loss: 1.9383, extra loss: 2.0981\n",
      "Epoch: 1, Step: 66, G Loss: 3.0264, D Loss: 2.9137, mask loss: 2.1518, extra loss: 1.7492\n",
      "Epoch: 1, Step: 67, G Loss: 3.0482, D Loss: 2.9137, mask loss: 2.1130, extra loss: 1.8705\n",
      "Epoch: 1, Step: 68, G Loss: 2.6350, D Loss: 2.9137, mask loss: 2.1936, extra loss: 0.8827\n",
      "Epoch: 1, Step: 69, G Loss: 2.6454, D Loss: 2.9137, mask loss: 2.3241, extra loss: 0.6426\n",
      "Epoch: 1, Step: 70, G Loss: 2.2924, D Loss: 2.9137, mask loss: 1.9470, extra loss: 0.6908\n",
      "Epoch: 1, Step: 71, G Loss: 3.5626, D Loss: 3.1957, mask loss: 1.8994, extra loss: 3.3263\n",
      "Epoch: 1, Step: 72, G Loss: 3.4781, D Loss: 3.1957, mask loss: 2.1261, extra loss: 2.7040\n",
      "Epoch: 1, Step: 73, G Loss: 2.8508, D Loss: 3.1957, mask loss: 1.8974, extra loss: 1.9068\n",
      "Epoch: 1, Step: 74, G Loss: 2.4485, D Loss: 3.1957, mask loss: 1.9936, extra loss: 0.9099\n",
      "Epoch: 1, Step: 75, G Loss: 2.4330, D Loss: 3.1957, mask loss: 2.0882, extra loss: 0.6896\n",
      "Epoch: 1, Step: 76, G Loss: 2.4928, D Loss: 3.1957, mask loss: 2.2205, extra loss: 0.5445\n",
      "Epoch: 1, Step: 77, G Loss: 2.3779, D Loss: 3.1957, mask loss: 2.1031, extra loss: 0.5496\n",
      "Epoch: 1, Step: 78, G Loss: 2.4680, D Loss: 3.1957, mask loss: 2.2264, extra loss: 0.4832\n",
      "Epoch: 1, Step: 79, G Loss: 2.5874, D Loss: 3.1957, mask loss: 2.3730, extra loss: 0.4288\n",
      "Epoch: 1, Step: 80, G Loss: 2.2663, D Loss: 3.1957, mask loss: 2.0989, extra loss: 0.3348\n",
      "Epoch: 1, Step: 81, G Loss: 3.1232, D Loss: 3.6743, mask loss: 1.9475, extra loss: 2.3514\n",
      "Epoch: 1, Step: 82, G Loss: 2.9582, D Loss: 3.6743, mask loss: 2.1024, extra loss: 1.7116\n",
      "Epoch: 1, Step: 83, G Loss: 2.6810, D Loss: 3.6743, mask loss: 2.1716, extra loss: 1.0188\n",
      "Epoch: 1, Step: 84, G Loss: 2.3460, D Loss: 3.6743, mask loss: 1.8670, extra loss: 0.9580\n",
      "Epoch: 1, Step: 85, G Loss: 2.5408, D Loss: 3.6743, mask loss: 2.2235, extra loss: 0.6347\n",
      "Epoch: 1, Step: 86, G Loss: 2.1244, D Loss: 3.6743, mask loss: 1.8244, extra loss: 0.6001\n",
      "Epoch: 1, Step: 87, G Loss: 2.2811, D Loss: 3.6743, mask loss: 2.0470, extra loss: 0.4681\n",
      "Epoch: 1, Step: 88, G Loss: 2.1135, D Loss: 3.6743, mask loss: 1.9494, extra loss: 0.3281\n",
      "Epoch: 1, Step: 89, G Loss: 2.0586, D Loss: 3.6743, mask loss: 1.8383, extra loss: 0.4406\n",
      "Epoch: 1, Step: 90, G Loss: 2.1717, D Loss: 3.6743, mask loss: 2.0504, extra loss: 0.2426\n",
      "Epoch: 1, Step: 91, G Loss: 2.9198, D Loss: 3.6935, mask loss: 1.9810, extra loss: 1.8776\n",
      "Epoch: 1, Step: 92, G Loss: 3.0160, D Loss: 3.6935, mask loss: 2.0216, extra loss: 1.9888\n",
      "Epoch: 1, Step: 93, G Loss: 2.6162, D Loss: 3.6935, mask loss: 1.9088, extra loss: 1.4147\n",
      "Epoch: 1, Step: 94, G Loss: 2.2056, D Loss: 3.6935, mask loss: 1.6784, extra loss: 1.0543\n",
      "Epoch: 1, Step: 95, G Loss: 2.4345, D Loss: 3.6935, mask loss: 1.9880, extra loss: 0.8931\n",
      "Epoch: 1, Step: 96, G Loss: 2.2066, D Loss: 3.6935, mask loss: 1.8668, extra loss: 0.6797\n",
      "Epoch: 1, Step: 97, G Loss: 2.1203, D Loss: 3.6935, mask loss: 1.9221, extra loss: 0.3964\n",
      "Epoch: 1, Step: 98, G Loss: 2.0827, D Loss: 3.6935, mask loss: 1.8852, extra loss: 0.3951\n",
      "Epoch: 1, Step: 99, G Loss: 2.1951, D Loss: 3.6935, mask loss: 1.9709, extra loss: 0.4484\n",
      "Epoch: 1, Step: 100, G Loss: 2.0089, D Loss: 3.6935, mask loss: 1.7569, extra loss: 0.5040\n",
      "Epoch: 1, Step: 101, G Loss: 2.9539, D Loss: 4.4499, mask loss: 2.0323, extra loss: 1.8431\n",
      "Epoch: 1, Step: 102, G Loss: 2.6036, D Loss: 4.4499, mask loss: 2.0149, extra loss: 1.1775\n",
      "Epoch: 1, Step: 103, G Loss: 2.7309, D Loss: 4.4499, mask loss: 2.0478, extra loss: 1.3662\n",
      "Epoch: 1, Step: 104, G Loss: 2.5170, D Loss: 4.4499, mask loss: 1.9251, extra loss: 1.1837\n",
      "Epoch: 1, Step: 105, G Loss: 2.5254, D Loss: 4.4499, mask loss: 2.0901, extra loss: 0.8707\n",
      "Epoch: 1, Step: 106, G Loss: 2.0245, D Loss: 4.4499, mask loss: 1.7158, extra loss: 0.6173\n",
      "Epoch: 1, Step: 107, G Loss: 2.0339, D Loss: 4.4499, mask loss: 1.7940, extra loss: 0.4797\n",
      "Epoch: 1, Step: 108, G Loss: 2.0220, D Loss: 4.4499, mask loss: 1.8081, extra loss: 0.4279\n",
      "Epoch: 1, Step: 109, G Loss: 2.1331, D Loss: 4.4499, mask loss: 1.9138, extra loss: 0.4385\n",
      "Epoch: 1, Step: 110, G Loss: 2.0970, D Loss: 4.4499, mask loss: 1.8983, extra loss: 0.3973\n",
      "Epoch: 1, Step: 111, G Loss: 2.8900, D Loss: 3.5613, mask loss: 1.9541, extra loss: 1.8719\n",
      "Epoch: 1, Step: 112, G Loss: 2.8131, D Loss: 3.5613, mask loss: 1.9751, extra loss: 1.6759\n",
      "Epoch: 1, Step: 113, G Loss: 2.3673, D Loss: 3.5613, mask loss: 1.7174, extra loss: 1.2998\n",
      "Epoch: 1, Step: 114, G Loss: 2.3323, D Loss: 3.5613, mask loss: 1.8264, extra loss: 1.0117\n",
      "Epoch: 1, Step: 115, G Loss: 2.3117, D Loss: 3.5613, mask loss: 1.8477, extra loss: 0.9281\n",
      "Epoch: 1, Step: 116, G Loss: 2.0270, D Loss: 3.5613, mask loss: 1.7489, extra loss: 0.5561\n",
      "Epoch: 1, Step: 117, G Loss: 2.2921, D Loss: 3.5613, mask loss: 2.0522, extra loss: 0.4799\n",
      "Epoch: 1, Step: 118, G Loss: 2.3247, D Loss: 3.5613, mask loss: 2.1330, extra loss: 0.3834\n",
      "Epoch: 1, Step: 119, G Loss: 2.1393, D Loss: 3.5613, mask loss: 2.0079, extra loss: 0.2627\n",
      "Epoch: 1, Step: 120, G Loss: 2.0117, D Loss: 3.5613, mask loss: 1.8914, extra loss: 0.2406\n",
      "Epoch: 1, Step: 121, G Loss: 2.8313, D Loss: 3.8847, mask loss: 2.0954, extra loss: 1.4718\n",
      "Epoch: 1, Step: 122, G Loss: 2.7944, D Loss: 3.8847, mask loss: 2.1185, extra loss: 1.3519\n",
      "Epoch: 1, Step: 123, G Loss: 2.4712, D Loss: 3.8847, mask loss: 1.9447, extra loss: 1.0531\n",
      "Epoch: 1, Step: 124, G Loss: 2.0014, D Loss: 3.8847, mask loss: 1.6213, extra loss: 0.7603\n",
      "Epoch: 1, Step: 125, G Loss: 2.3446, D Loss: 3.8847, mask loss: 2.0779, extra loss: 0.5334\n",
      "Epoch: 1, Step: 126, G Loss: 2.1571, D Loss: 3.8847, mask loss: 1.9119, extra loss: 0.4904\n",
      "Epoch: 1, Step: 127, G Loss: 2.2998, D Loss: 3.8847, mask loss: 2.0306, extra loss: 0.5383\n",
      "Epoch: 1, Step: 128, G Loss: 2.0049, D Loss: 3.8847, mask loss: 1.8011, extra loss: 0.4075\n",
      "Epoch: 1, Step: 129, G Loss: 2.1290, D Loss: 3.8847, mask loss: 1.9901, extra loss: 0.2779\n",
      "Epoch: 1, Step: 130, G Loss: 1.8296, D Loss: 3.8847, mask loss: 1.6899, extra loss: 0.2794\n",
      "Epoch: 1, Step: 131, G Loss: 2.0242, D Loss: 3.2890, mask loss: 1.5672, extra loss: 0.9140\n",
      "Epoch: 1, Step: 132, G Loss: 2.3458, D Loss: 3.2890, mask loss: 1.9472, extra loss: 0.7972\n",
      "Epoch: 1, Step: 133, G Loss: 2.0993, D Loss: 3.2890, mask loss: 1.7628, extra loss: 0.6730\n",
      "Epoch: 1, Step: 134, G Loss: 1.9438, D Loss: 3.2890, mask loss: 1.7288, extra loss: 0.4300\n",
      "Epoch: 1, Step: 135, G Loss: 2.2824, D Loss: 3.2890, mask loss: 2.0774, extra loss: 0.4099\n",
      "Epoch: 1, Step: 136, G Loss: 1.7753, D Loss: 3.2890, mask loss: 1.6156, extra loss: 0.3195\n",
      "Epoch: 1, Step: 137, G Loss: 1.9668, D Loss: 3.2890, mask loss: 1.8295, extra loss: 0.2747\n",
      "Epoch: 1, Step: 138, G Loss: 1.8820, D Loss: 3.2890, mask loss: 1.7575, extra loss: 0.2491\n",
      "Epoch: 1, Step: 139, G Loss: 1.7659, D Loss: 3.2890, mask loss: 1.6851, extra loss: 0.1616\n",
      "Epoch: 1, Step: 140, G Loss: 1.6565, D Loss: 3.2890, mask loss: 1.5501, extra loss: 0.2130\n",
      "Epoch: 1, Step: 141, G Loss: 2.5422, D Loss: 3.9979, mask loss: 2.0439, extra loss: 0.9967\n",
      "Epoch: 1, Step: 142, G Loss: 2.2026, D Loss: 3.9979, mask loss: 1.7999, extra loss: 0.8053\n",
      "Epoch: 1, Step: 143, G Loss: 2.1638, D Loss: 3.9979, mask loss: 1.8310, extra loss: 0.6656\n",
      "Epoch: 1, Step: 144, G Loss: 1.8700, D Loss: 3.9979, mask loss: 1.5914, extra loss: 0.5573\n",
      "Epoch: 1, Step: 145, G Loss: 1.9600, D Loss: 3.9979, mask loss: 1.7334, extra loss: 0.4533\n",
      "Epoch: 1, Step: 146, G Loss: 2.0263, D Loss: 3.9979, mask loss: 1.7483, extra loss: 0.5559\n",
      "Epoch: 1, Step: 147, G Loss: 1.8614, D Loss: 3.9979, mask loss: 1.6591, extra loss: 0.4046\n",
      "Epoch: 1, Step: 148, G Loss: 1.6992, D Loss: 3.9979, mask loss: 1.5449, extra loss: 0.3086\n",
      "Epoch: 1, Step: 149, G Loss: 1.8974, D Loss: 3.9979, mask loss: 1.7858, extra loss: 0.2232\n",
      "Epoch: 1, Step: 150, G Loss: 1.7969, D Loss: 3.9979, mask loss: 1.6983, extra loss: 0.1972\n",
      "Epoch: 1, Step: 151, G Loss: 2.0857, D Loss: 3.4346, mask loss: 1.5991, extra loss: 0.9732\n",
      "Epoch: 1, Step: 152, G Loss: 2.4682, D Loss: 3.4346, mask loss: 1.9339, extra loss: 1.0685\n",
      "Epoch: 1, Step: 153, G Loss: 2.1593, D Loss: 3.4346, mask loss: 1.7434, extra loss: 0.8318\n",
      "Epoch: 1, Step: 154, G Loss: 2.0351, D Loss: 3.4346, mask loss: 1.7193, extra loss: 0.6316\n",
      "Epoch: 1, Step: 155, G Loss: 1.8108, D Loss: 3.4346, mask loss: 1.5023, extra loss: 0.6170\n",
      "Epoch: 1, Step: 156, G Loss: 2.0208, D Loss: 3.4346, mask loss: 1.7652, extra loss: 0.5113\n",
      "Epoch: 1, Step: 157, G Loss: 1.7892, D Loss: 3.4346, mask loss: 1.5562, extra loss: 0.4661\n",
      "Epoch: 1, Step: 158, G Loss: 1.6459, D Loss: 3.4346, mask loss: 1.4387, extra loss: 0.4144\n",
      "Epoch: 1, Step: 159, G Loss: 1.6119, D Loss: 3.4346, mask loss: 1.4818, extra loss: 0.2602\n",
      "Epoch: 1, Step: 160, G Loss: 1.8545, D Loss: 3.4346, mask loss: 1.7487, extra loss: 0.2114\n",
      "Epoch: 1, Step: 161, G Loss: 2.3272, D Loss: 3.8343, mask loss: 1.7518, extra loss: 1.1506\n",
      "Epoch: 1, Step: 162, G Loss: 2.0570, D Loss: 3.8343, mask loss: 1.6281, extra loss: 0.8577\n",
      "Epoch: 1, Step: 163, G Loss: 1.9132, D Loss: 3.8343, mask loss: 1.5353, extra loss: 0.7559\n",
      "Epoch: 1, Step: 164, G Loss: 2.0072, D Loss: 3.8343, mask loss: 1.6467, extra loss: 0.7210\n",
      "Epoch: 1, Step: 165, G Loss: 1.8327, D Loss: 3.8343, mask loss: 1.5876, extra loss: 0.4902\n",
      "Epoch: 1, Step: 166, G Loss: 1.5971, D Loss: 3.8343, mask loss: 1.3384, extra loss: 0.5173\n",
      "Epoch: 1, Step: 167, G Loss: 1.8095, D Loss: 3.8343, mask loss: 1.5691, extra loss: 0.4808\n",
      "Epoch: 1, Step: 168, G Loss: 2.0220, D Loss: 3.8343, mask loss: 1.7667, extra loss: 0.5106\n",
      "Epoch: 1, Step: 169, G Loss: 1.7821, D Loss: 3.8343, mask loss: 1.6108, extra loss: 0.3426\n",
      "Epoch: 1, Step: 170, G Loss: 1.6251, D Loss: 3.8343, mask loss: 1.4909, extra loss: 0.2685\n",
      "Epoch: 1, Step: 171, G Loss: 2.3667, D Loss: 3.6350, mask loss: 1.7827, extra loss: 1.1679\n",
      "Epoch: 1, Step: 172, G Loss: 1.9169, D Loss: 3.6350, mask loss: 1.5221, extra loss: 0.7895\n",
      "Epoch: 1, Step: 173, G Loss: 2.1946, D Loss: 3.6350, mask loss: 1.7904, extra loss: 0.8083\n",
      "Epoch: 1, Step: 174, G Loss: 2.2972, D Loss: 3.6350, mask loss: 1.9627, extra loss: 0.6691\n",
      "Epoch: 1, Step: 175, G Loss: 2.2005, D Loss: 3.6350, mask loss: 1.9224, extra loss: 0.5562\n",
      "Epoch: 1, Step: 176, G Loss: 1.8414, D Loss: 3.6350, mask loss: 1.6348, extra loss: 0.4133\n",
      "Epoch: 1, Step: 177, G Loss: 2.0081, D Loss: 3.6350, mask loss: 1.7796, extra loss: 0.4571\n",
      "Epoch: 1, Step: 178, G Loss: 2.0290, D Loss: 3.6350, mask loss: 1.8953, extra loss: 0.2673\n",
      "Epoch: 1, Step: 179, G Loss: 1.7465, D Loss: 3.6350, mask loss: 1.6213, extra loss: 0.2503\n",
      "Epoch: 1, Step: 180, G Loss: 2.0344, D Loss: 3.6350, mask loss: 1.9108, extra loss: 0.2473\n",
      "Epoch: 1, Step: 181, G Loss: 2.0812, D Loss: 3.9828, mask loss: 1.6519, extra loss: 0.8586\n",
      "Epoch: 1, Step: 182, G Loss: 1.9900, D Loss: 3.9828, mask loss: 1.5748, extra loss: 0.8304\n",
      "Epoch: 1, Step: 183, G Loss: 1.8815, D Loss: 3.9828, mask loss: 1.5880, extra loss: 0.5870\n",
      "Epoch: 1, Step: 184, G Loss: 2.2153, D Loss: 3.9828, mask loss: 1.8029, extra loss: 0.8248\n",
      "Epoch: 1, Step: 185, G Loss: 1.9898, D Loss: 3.9828, mask loss: 1.6886, extra loss: 0.6023\n",
      "Epoch: 1, Step: 186, G Loss: 1.9017, D Loss: 3.9828, mask loss: 1.5956, extra loss: 0.6123\n",
      "Epoch: 1, Step: 187, G Loss: 2.0892, D Loss: 3.9828, mask loss: 1.9294, extra loss: 0.3198\n",
      "Epoch: 1, Step: 188, G Loss: 1.8610, D Loss: 3.9828, mask loss: 1.6022, extra loss: 0.5177\n",
      "Epoch: 1, Step: 189, G Loss: 1.7315, D Loss: 3.9828, mask loss: 1.6097, extra loss: 0.2436\n",
      "Epoch: 1, Step: 190, G Loss: 1.5703, D Loss: 3.9828, mask loss: 1.4153, extra loss: 0.3100\n",
      "Epoch: 1, Step: 191, G Loss: 2.2185, D Loss: 4.4534, mask loss: 1.7424, extra loss: 0.9523\n",
      "Epoch: 1, Step: 192, G Loss: 1.9227, D Loss: 4.4534, mask loss: 1.6822, extra loss: 0.4809\n",
      "Epoch: 1, Step: 193, G Loss: 1.8389, D Loss: 4.4534, mask loss: 1.5705, extra loss: 0.5367\n",
      "Epoch: 1, Step: 194, G Loss: 2.0379, D Loss: 4.4534, mask loss: 1.8378, extra loss: 0.4002\n",
      "Epoch: 1, Step: 195, G Loss: 1.9413, D Loss: 4.4534, mask loss: 1.6752, extra loss: 0.5322\n",
      "Epoch: 1, Step: 196, G Loss: 1.8194, D Loss: 4.4534, mask loss: 1.6569, extra loss: 0.3250\n",
      "Epoch: 1, Step: 197, G Loss: 1.7912, D Loss: 4.4534, mask loss: 1.6116, extra loss: 0.3590\n",
      "Epoch: 1, Step: 198, G Loss: 1.9387, D Loss: 4.4534, mask loss: 1.7894, extra loss: 0.2986\n",
      "Epoch: 1, Step: 199, G Loss: 1.6445, D Loss: 4.4534, mask loss: 1.5148, extra loss: 0.2594\n",
      "Epoch: 1, Step: 200, G Loss: 1.7862, D Loss: 4.4534, mask loss: 1.6699, extra loss: 0.2326\n",
      "Epoch: 1, Step: 201, G Loss: 1.8856, D Loss: 4.0218, mask loss: 1.5545, extra loss: 0.6622\n",
      "Epoch: 1, Step: 202, G Loss: 1.9268, D Loss: 4.0218, mask loss: 1.6282, extra loss: 0.5972\n",
      "Epoch: 1, Step: 203, G Loss: 1.9491, D Loss: 4.0218, mask loss: 1.5090, extra loss: 0.8801\n",
      "Epoch: 1, Step: 204, G Loss: 1.9041, D Loss: 4.0218, mask loss: 1.6788, extra loss: 0.4507\n",
      "Epoch: 1, Step: 205, G Loss: 1.7917, D Loss: 4.0218, mask loss: 1.5835, extra loss: 0.4165\n",
      "Epoch: 1, Step: 206, G Loss: 2.0384, D Loss: 4.0218, mask loss: 1.7885, extra loss: 0.4999\n",
      "Epoch: 1, Step: 207, G Loss: 1.7800, D Loss: 4.0218, mask loss: 1.6081, extra loss: 0.3438\n",
      "Epoch: 1, Step: 208, G Loss: 1.9303, D Loss: 4.0218, mask loss: 1.7457, extra loss: 0.3692\n",
      "Epoch: 1, Step: 209, G Loss: 1.6752, D Loss: 4.0218, mask loss: 1.5211, extra loss: 0.3083\n",
      "Epoch: 1, Step: 210, G Loss: 1.6012, D Loss: 4.0218, mask loss: 1.4670, extra loss: 0.2683\n",
      "Epoch: 1, Step: 211, G Loss: 2.0429, D Loss: 3.9701, mask loss: 1.6097, extra loss: 0.8663\n",
      "Epoch: 1, Step: 212, G Loss: 1.8149, D Loss: 3.9701, mask loss: 1.4461, extra loss: 0.7377\n",
      "Epoch: 1, Step: 213, G Loss: 2.0221, D Loss: 3.9701, mask loss: 1.6890, extra loss: 0.6661\n",
      "Epoch: 1, Step: 214, G Loss: 1.7113, D Loss: 3.9701, mask loss: 1.3695, extra loss: 0.6835\n",
      "Epoch: 1, Step: 215, G Loss: 1.9131, D Loss: 3.9701, mask loss: 1.6459, extra loss: 0.5342\n",
      "Epoch: 1, Step: 216, G Loss: 1.7684, D Loss: 3.9701, mask loss: 1.5527, extra loss: 0.4313\n",
      "Epoch: 1, Step: 217, G Loss: 1.7946, D Loss: 3.9701, mask loss: 1.5401, extra loss: 0.5091\n",
      "Epoch: 1, Step: 218, G Loss: 2.0253, D Loss: 3.9701, mask loss: 1.8187, extra loss: 0.4131\n",
      "Epoch: 1, Step: 219, G Loss: 1.7125, D Loss: 3.9701, mask loss: 1.5335, extra loss: 0.3580\n",
      "Epoch: 1, Step: 220, G Loss: 1.8069, D Loss: 3.9701, mask loss: 1.6381, extra loss: 0.3376\n",
      "Epoch: 1, Step: 221, G Loss: 2.2470, D Loss: 3.6508, mask loss: 1.7749, extra loss: 0.9443\n",
      "Epoch: 1, Step: 222, G Loss: 1.9166, D Loss: 3.6508, mask loss: 1.5608, extra loss: 0.7117\n",
      "Epoch: 1, Step: 223, G Loss: 2.0168, D Loss: 3.6508, mask loss: 1.7111, extra loss: 0.6114\n",
      "Epoch: 1, Step: 224, G Loss: 2.2410, D Loss: 3.6508, mask loss: 1.8885, extra loss: 0.7051\n",
      "Epoch: 1, Step: 225, G Loss: 1.8331, D Loss: 3.6508, mask loss: 1.6001, extra loss: 0.4659\n",
      "Epoch: 1, Step: 226, G Loss: 1.9629, D Loss: 3.6508, mask loss: 1.7230, extra loss: 0.4799\n",
      "Epoch: 1, Step: 227, G Loss: 1.7063, D Loss: 3.6508, mask loss: 1.4556, extra loss: 0.5013\n",
      "Epoch: 1, Step: 228, G Loss: 1.8790, D Loss: 3.6508, mask loss: 1.5393, extra loss: 0.6794\n",
      "Epoch: 1, Step: 229, G Loss: 1.8460, D Loss: 3.6508, mask loss: 1.6533, extra loss: 0.3855\n",
      "Epoch: 1, Step: 230, G Loss: 1.5829, D Loss: 3.6508, mask loss: 1.3684, extra loss: 0.4290\n",
      "Epoch: 1, Step: 231, G Loss: 1.9187, D Loss: 3.0554, mask loss: 1.5550, extra loss: 0.7274\n",
      "Epoch: 1, Step: 232, G Loss: 1.7233, D Loss: 3.0554, mask loss: 1.4051, extra loss: 0.6364\n",
      "Epoch: 1, Step: 233, G Loss: 1.9973, D Loss: 3.0554, mask loss: 1.6742, extra loss: 0.6462\n",
      "Epoch: 1, Step: 234, G Loss: 2.2538, D Loss: 3.0554, mask loss: 1.9168, extra loss: 0.6742\n",
      "Epoch: 1, Step: 235, G Loss: 1.9395, D Loss: 3.0554, mask loss: 1.6770, extra loss: 0.5250\n",
      "Epoch: 1, Step: 236, G Loss: 1.8427, D Loss: 3.0554, mask loss: 1.5606, extra loss: 0.5642\n",
      "Epoch: 1, Step: 237, G Loss: 1.8426, D Loss: 3.0554, mask loss: 1.5458, extra loss: 0.5937\n",
      "Epoch: 1, Step: 238, G Loss: 1.9282, D Loss: 3.0554, mask loss: 1.6533, extra loss: 0.5496\n",
      "Epoch: 1, Step: 239, G Loss: 1.6978, D Loss: 3.0554, mask loss: 1.5049, extra loss: 0.3858\n",
      "Epoch: 1, Step: 240, G Loss: 1.6905, D Loss: 3.0554, mask loss: 1.5132, extra loss: 0.3546\n",
      "Epoch: 1, Step: 241, G Loss: 1.9650, D Loss: 3.1594, mask loss: 1.6508, extra loss: 0.6283\n",
      "Epoch: 1, Step: 242, G Loss: 1.9010, D Loss: 3.1594, mask loss: 1.5449, extra loss: 0.7123\n",
      "Epoch: 1, Step: 243, G Loss: 1.6732, D Loss: 3.1594, mask loss: 1.4008, extra loss: 0.5449\n",
      "Epoch: 1, Step: 244, G Loss: 1.7254, D Loss: 3.1594, mask loss: 1.4276, extra loss: 0.5958\n",
      "Epoch: 1, Step: 245, G Loss: 1.9305, D Loss: 3.1594, mask loss: 1.6720, extra loss: 0.5170\n",
      "Epoch: 1, Step: 246, G Loss: 1.7457, D Loss: 3.1594, mask loss: 1.4891, extra loss: 0.5132\n",
      "Epoch: 1, Step: 247, G Loss: 1.9380, D Loss: 3.1594, mask loss: 1.6800, extra loss: 0.5160\n",
      "Epoch: 1, Step: 248, G Loss: 1.5721, D Loss: 3.1594, mask loss: 1.3434, extra loss: 0.4573\n",
      "Epoch: 1, Step: 249, G Loss: 1.7128, D Loss: 3.1594, mask loss: 1.4939, extra loss: 0.4377\n",
      "Epoch: 1, Step: 250, G Loss: 1.6133, D Loss: 3.1594, mask loss: 1.4077, extra loss: 0.4112\n",
      "Epoch: 1, Step: 251, G Loss: 1.6773, D Loss: 2.7272, mask loss: 1.3980, extra loss: 0.5586\n",
      "Epoch: 1, Step: 252, G Loss: 1.7982, D Loss: 2.7272, mask loss: 1.5309, extra loss: 0.5346\n",
      "Epoch: 1, Step: 253, G Loss: 1.6884, D Loss: 2.7272, mask loss: 1.3820, extra loss: 0.6128\n",
      "Epoch: 1, Step: 254, G Loss: 1.6674, D Loss: 2.7272, mask loss: 1.4236, extra loss: 0.4877\n",
      "Epoch: 1, Step: 255, G Loss: 1.8319, D Loss: 2.7272, mask loss: 1.5964, extra loss: 0.4710\n",
      "Epoch: 1, Step: 256, G Loss: 1.5026, D Loss: 2.7272, mask loss: 1.2748, extra loss: 0.4557\n",
      "Epoch: 1, Step: 257, G Loss: 1.7220, D Loss: 2.7272, mask loss: 1.4909, extra loss: 0.4622\n",
      "Epoch: 1, Step: 258, G Loss: 1.8929, D Loss: 2.7272, mask loss: 1.6727, extra loss: 0.4404\n",
      "Epoch: 1, Step: 259, G Loss: 1.7014, D Loss: 2.7272, mask loss: 1.4859, extra loss: 0.4311\n",
      "Epoch: 1, Step: 260, G Loss: 1.7608, D Loss: 2.7272, mask loss: 1.5553, extra loss: 0.4111\n",
      "Epoch: 1, Step: 261, G Loss: 1.7981, D Loss: 2.6659, mask loss: 1.5646, extra loss: 0.4670\n",
      "Epoch: 1, Step: 262, G Loss: 1.6363, D Loss: 2.6659, mask loss: 1.3769, extra loss: 0.5188\n",
      "Epoch: 1, Step: 263, G Loss: 1.6527, D Loss: 2.6659, mask loss: 1.3980, extra loss: 0.5093\n",
      "Epoch: 1, Step: 264, G Loss: 1.7847, D Loss: 2.6659, mask loss: 1.5494, extra loss: 0.4707\n",
      "Epoch: 1, Step: 265, G Loss: 1.7441, D Loss: 2.6659, mask loss: 1.5193, extra loss: 0.4496\n",
      "Epoch: 1, Step: 266, G Loss: 1.6836, D Loss: 2.6659, mask loss: 1.4427, extra loss: 0.4819\n",
      "Epoch: 1, Step: 267, G Loss: 1.5984, D Loss: 2.6659, mask loss: 1.3097, extra loss: 0.5772\n",
      "Epoch: 1, Step: 268, G Loss: 1.4408, D Loss: 2.6659, mask loss: 1.2187, extra loss: 0.4442\n",
      "Epoch: 1, Step: 269, G Loss: 1.7646, D Loss: 2.6659, mask loss: 1.5376, extra loss: 0.4539\n",
      "Epoch: 1, Step: 270, G Loss: 1.4432, D Loss: 2.6659, mask loss: 1.2356, extra loss: 0.4152\n",
      "Epoch: 1, Step: 271, G Loss: 1.3952, D Loss: 2.3470, mask loss: 1.1311, extra loss: 0.5281\n",
      "Epoch: 1, Step: 272, G Loss: 1.7024, D Loss: 2.3470, mask loss: 1.4447, extra loss: 0.5153\n",
      "Epoch: 1, Step: 273, G Loss: 1.6941, D Loss: 2.3470, mask loss: 1.4552, extra loss: 0.4777\n",
      "Epoch: 1, Step: 274, G Loss: 1.5722, D Loss: 2.3470, mask loss: 1.3470, extra loss: 0.4504\n",
      "Epoch: 1, Step: 275, G Loss: 1.5750, D Loss: 2.3470, mask loss: 1.3286, extra loss: 0.4928\n",
      "Epoch: 1, Step: 276, G Loss: 1.5210, D Loss: 2.3470, mask loss: 1.2606, extra loss: 0.5208\n",
      "Epoch: 1, Step: 277, G Loss: 1.5718, D Loss: 2.3470, mask loss: 1.3459, extra loss: 0.4518\n",
      "Epoch: 1, Step: 278, G Loss: 1.6477, D Loss: 2.3470, mask loss: 1.4069, extra loss: 0.4816\n",
      "Epoch: 1, Step: 279, G Loss: 1.6442, D Loss: 2.3470, mask loss: 1.3833, extra loss: 0.5217\n",
      "Epoch: 1, Step: 280, G Loss: 1.4422, D Loss: 2.3470, mask loss: 1.2242, extra loss: 0.4361\n",
      "Epoch: 1, Step: 281, G Loss: 1.6846, D Loss: 2.5450, mask loss: 1.4098, extra loss: 0.5496\n",
      "Epoch: 1, Step: 282, G Loss: 1.3717, D Loss: 2.5450, mask loss: 1.0959, extra loss: 0.5515\n",
      "Epoch: 1, Step: 283, G Loss: 1.4058, D Loss: 2.5450, mask loss: 1.1323, extra loss: 0.5469\n",
      "Epoch: 1, Step: 284, G Loss: 1.6774, D Loss: 2.5450, mask loss: 1.4189, extra loss: 0.5170\n",
      "Epoch: 1, Step: 285, G Loss: 1.5294, D Loss: 2.5450, mask loss: 1.2599, extra loss: 0.5388\n",
      "Epoch: 1, Step: 286, G Loss: 1.7386, D Loss: 2.5450, mask loss: 1.4525, extra loss: 0.5721\n",
      "Epoch: 1, Step: 287, G Loss: 1.4474, D Loss: 2.5450, mask loss: 1.1748, extra loss: 0.5452\n",
      "Epoch: 1, Step: 288, G Loss: 1.6152, D Loss: 2.5450, mask loss: 1.3505, extra loss: 0.5294\n",
      "Epoch: 1, Step: 289, G Loss: 1.6742, D Loss: 2.5450, mask loss: 1.4216, extra loss: 0.5052\n",
      "Epoch: 1, Step: 290, G Loss: 1.5883, D Loss: 2.5450, mask loss: 1.3004, extra loss: 0.5759\n",
      "Epoch: 1, Step: 291, G Loss: 1.5466, D Loss: 2.0113, mask loss: 1.2473, extra loss: 0.5986\n",
      "Epoch: 1, Step: 292, G Loss: 1.6859, D Loss: 2.0113, mask loss: 1.3380, extra loss: 0.6958\n",
      "Epoch: 1, Step: 293, G Loss: 1.6039, D Loss: 2.0113, mask loss: 1.2784, extra loss: 0.6510\n",
      "Epoch: 1, Step: 294, G Loss: 1.8515, D Loss: 2.0113, mask loss: 1.5488, extra loss: 0.6054\n",
      "Epoch: 1, Step: 295, G Loss: 1.6777, D Loss: 2.0113, mask loss: 1.3479, extra loss: 0.6597\n",
      "Epoch: 1, Step: 296, G Loss: 1.6986, D Loss: 2.0113, mask loss: 1.3937, extra loss: 0.6098\n",
      "Epoch: 1, Step: 297, G Loss: 1.6884, D Loss: 2.0113, mask loss: 1.3988, extra loss: 0.5791\n",
      "Epoch: 1, Step: 298, G Loss: 1.7894, D Loss: 2.0113, mask loss: 1.4762, extra loss: 0.6265\n",
      "Epoch: 1, Step: 299, G Loss: 1.5740, D Loss: 2.0113, mask loss: 1.2860, extra loss: 0.5760\n",
      "Epoch: 1, Step: 300, G Loss: 1.6896, D Loss: 2.0113, mask loss: 1.3909, extra loss: 0.5973\n",
      "Epoch: 1, Step: 301, G Loss: 1.7478, D Loss: 2.0237, mask loss: 1.4682, extra loss: 0.5593\n",
      "Epoch: 1, Step: 302, G Loss: 1.5974, D Loss: 2.0237, mask loss: 1.2885, extra loss: 0.6179\n",
      "Epoch: 1, Step: 303, G Loss: 1.6464, D Loss: 2.0237, mask loss: 1.3530, extra loss: 0.5868\n",
      "Epoch: 1, Step: 304, G Loss: 1.6426, D Loss: 2.0237, mask loss: 1.2981, extra loss: 0.6890\n",
      "Epoch: 1, G Loss: 2.2150(Mask Loss: 1.7867, Extra Loss: 0.8567), D Loss: 3.0135, Train FID: 247.4045, Val FID: 254.5520\n",
      "Epoch: 2, Step: 1, G Loss: 1.7256, D Loss: 1.9230, mask loss: 1.3666, extra loss: 0.7180\n",
      "Epoch: 2, Step: 2, G Loss: 1.6492, D Loss: 1.9230, mask loss: 1.3082, extra loss: 0.6821\n",
      "Epoch: 2, Step: 3, G Loss: 1.6950, D Loss: 1.9230, mask loss: 1.3401, extra loss: 0.7097\n",
      "Epoch: 2, Step: 4, G Loss: 1.6848, D Loss: 1.9230, mask loss: 1.3642, extra loss: 0.6412\n",
      "Epoch: 2, Step: 5, G Loss: 1.6303, D Loss: 1.9230, mask loss: 1.3029, extra loss: 0.6548\n",
      "Epoch: 2, Step: 6, G Loss: 1.5857, D Loss: 1.9230, mask loss: 1.2442, extra loss: 0.6831\n",
      "Epoch: 2, Step: 7, G Loss: 1.7180, D Loss: 1.9230, mask loss: 1.3701, extra loss: 0.6957\n",
      "Epoch: 2, Step: 8, G Loss: 1.5889, D Loss: 1.9230, mask loss: 1.2728, extra loss: 0.6323\n",
      "Epoch: 2, Step: 9, G Loss: 1.5381, D Loss: 1.9230, mask loss: 1.2030, extra loss: 0.6703\n",
      "Epoch: 2, Step: 10, G Loss: 1.6544, D Loss: 1.9230, mask loss: 1.3396, extra loss: 0.6295\n",
      "Epoch: 2, Step: 11, G Loss: 1.5790, D Loss: 1.8998, mask loss: 1.1864, extra loss: 0.7852\n",
      "Epoch: 2, Step: 12, G Loss: 1.7684, D Loss: 1.8998, mask loss: 1.3828, extra loss: 0.7713\n",
      "Epoch: 2, Step: 13, G Loss: 1.6150, D Loss: 1.8998, mask loss: 1.2288, extra loss: 0.7725\n",
      "Epoch: 2, Step: 14, G Loss: 1.5955, D Loss: 1.8998, mask loss: 1.2173, extra loss: 0.7564\n",
      "Epoch: 2, Step: 15, G Loss: 1.9312, D Loss: 1.8998, mask loss: 1.5798, extra loss: 0.7028\n",
      "Epoch: 2, Step: 16, G Loss: 1.6243, D Loss: 1.8998, mask loss: 1.2666, extra loss: 0.7154\n",
      "Epoch: 2, Step: 17, G Loss: 1.5912, D Loss: 1.8998, mask loss: 1.2401, extra loss: 0.7022\n",
      "Epoch: 2, Step: 18, G Loss: 1.6466, D Loss: 1.8998, mask loss: 1.2879, extra loss: 0.7176\n",
      "Epoch: 2, Step: 19, G Loss: 1.7148, D Loss: 1.8998, mask loss: 1.3654, extra loss: 0.6987\n",
      "Epoch: 2, Step: 20, G Loss: 1.4574, D Loss: 1.8998, mask loss: 1.0944, extra loss: 0.7261\n",
      "Epoch: 2, Step: 21, G Loss: 1.4701, D Loss: 1.8070, mask loss: 1.0829, extra loss: 0.7744\n",
      "Epoch: 2, Step: 22, G Loss: 1.7032, D Loss: 1.8070, mask loss: 1.3490, extra loss: 0.7084\n",
      "Epoch: 2, Step: 23, G Loss: 1.8212, D Loss: 1.8070, mask loss: 1.4313, extra loss: 0.7799\n",
      "Epoch: 2, Step: 24, G Loss: 1.7751, D Loss: 1.8070, mask loss: 1.4003, extra loss: 0.7497\n",
      "Epoch: 2, Step: 25, G Loss: 1.8182, D Loss: 1.8070, mask loss: 1.4288, extra loss: 0.7788\n",
      "Epoch: 2, Step: 26, G Loss: 1.8482, D Loss: 1.8070, mask loss: 1.4454, extra loss: 0.8056\n",
      "Epoch: 2, Step: 27, G Loss: 1.5908, D Loss: 1.8070, mask loss: 1.2086, extra loss: 0.7646\n",
      "Epoch: 2, Step: 28, G Loss: 1.7121, D Loss: 1.8070, mask loss: 1.3307, extra loss: 0.7630\n",
      "Epoch: 2, Step: 29, G Loss: 1.6352, D Loss: 1.8070, mask loss: 1.2562, extra loss: 0.7581\n",
      "Epoch: 2, Step: 30, G Loss: 1.7514, D Loss: 1.8070, mask loss: 1.3808, extra loss: 0.7411\n",
      "Epoch: 2, Step: 31, G Loss: 1.7357, D Loss: 1.9221, mask loss: 1.3279, extra loss: 0.8156\n",
      "Epoch: 2, Step: 32, G Loss: 1.5203, D Loss: 1.9221, mask loss: 1.1371, extra loss: 0.7664\n",
      "Epoch: 2, Step: 33, G Loss: 1.5816, D Loss: 1.9221, mask loss: 1.1919, extra loss: 0.7793\n",
      "Epoch: 2, Step: 34, G Loss: 1.9288, D Loss: 1.9221, mask loss: 1.5365, extra loss: 0.7846\n",
      "Epoch: 2, Step: 35, G Loss: 1.6568, D Loss: 1.9221, mask loss: 1.2782, extra loss: 0.7572\n",
      "Epoch: 2, Step: 36, G Loss: 1.6450, D Loss: 1.9221, mask loss: 1.2997, extra loss: 0.6907\n",
      "Epoch: 2, Step: 37, G Loss: 1.7094, D Loss: 1.9221, mask loss: 1.3776, extra loss: 0.6635\n",
      "Epoch: 2, Step: 38, G Loss: 1.6521, D Loss: 1.9221, mask loss: 1.2918, extra loss: 0.7205\n",
      "Epoch: 2, Step: 39, G Loss: 1.6856, D Loss: 1.9221, mask loss: 1.3632, extra loss: 0.6448\n",
      "Epoch: 2, Step: 40, G Loss: 1.7570, D Loss: 1.9221, mask loss: 1.4033, extra loss: 0.7074\n",
      "Epoch: 2, Step: 41, G Loss: 1.5965, D Loss: 1.8509, mask loss: 1.2675, extra loss: 0.6578\n",
      "Epoch: 2, Step: 42, G Loss: 1.4829, D Loss: 1.8509, mask loss: 1.1281, extra loss: 0.7096\n",
      "Epoch: 2, Step: 43, G Loss: 1.5449, D Loss: 1.8509, mask loss: 1.2137, extra loss: 0.6624\n",
      "Epoch: 2, Step: 44, G Loss: 1.6075, D Loss: 1.8509, mask loss: 1.2193, extra loss: 0.7764\n",
      "Epoch: 2, Step: 45, G Loss: 1.8516, D Loss: 1.8509, mask loss: 1.4731, extra loss: 0.7570\n",
      "Epoch: 2, Step: 46, G Loss: 1.8238, D Loss: 1.8509, mask loss: 1.4564, extra loss: 0.7349\n",
      "Epoch: 2, Step: 47, G Loss: 1.5416, D Loss: 1.8509, mask loss: 1.1717, extra loss: 0.7399\n",
      "Epoch: 2, Step: 48, G Loss: 1.6847, D Loss: 1.8509, mask loss: 1.3758, extra loss: 0.6177\n",
      "Epoch: 2, Step: 49, G Loss: 1.3764, D Loss: 1.8509, mask loss: 1.0479, extra loss: 0.6569\n",
      "Epoch: 2, Step: 50, G Loss: 1.5730, D Loss: 1.8509, mask loss: 1.2656, extra loss: 0.6146\n",
      "Epoch: 2, Step: 51, G Loss: 1.4625, D Loss: 1.8321, mask loss: 1.1709, extra loss: 0.5834\n",
      "Epoch: 2, Step: 52, G Loss: 1.5286, D Loss: 1.8321, mask loss: 1.2408, extra loss: 0.5756\n",
      "Epoch: 2, Step: 53, G Loss: 1.5340, D Loss: 1.8321, mask loss: 1.2592, extra loss: 0.5496\n",
      "Epoch: 2, Step: 54, G Loss: 1.5429, D Loss: 1.8321, mask loss: 1.2664, extra loss: 0.5529\n",
      "Epoch: 2, Step: 55, G Loss: 1.7487, D Loss: 1.8321, mask loss: 1.4859, extra loss: 0.5256\n",
      "Epoch: 2, Step: 56, G Loss: 1.5120, D Loss: 1.8321, mask loss: 1.2554, extra loss: 0.5133\n",
      "Epoch: 2, Step: 57, G Loss: 1.3324, D Loss: 1.8321, mask loss: 1.0631, extra loss: 0.5386\n",
      "Epoch: 2, Step: 58, G Loss: 1.5181, D Loss: 1.8321, mask loss: 1.2310, extra loss: 0.5742\n",
      "Epoch: 2, Step: 59, G Loss: 1.6482, D Loss: 1.8321, mask loss: 1.4133, extra loss: 0.4697\n",
      "Epoch: 2, Step: 60, G Loss: 1.5703, D Loss: 1.8321, mask loss: 1.3042, extra loss: 0.5322\n",
      "Epoch: 2, Step: 61, G Loss: 1.6179, D Loss: 1.8363, mask loss: 1.3373, extra loss: 0.5613\n",
      "Epoch: 2, Step: 62, G Loss: 1.5775, D Loss: 1.8363, mask loss: 1.2216, extra loss: 0.7117\n",
      "Epoch: 2, Step: 63, G Loss: 1.6714, D Loss: 1.8363, mask loss: 1.3757, extra loss: 0.5915\n",
      "Epoch: 2, Step: 64, G Loss: 1.4659, D Loss: 1.8363, mask loss: 1.1943, extra loss: 0.5432\n",
      "Epoch: 2, Step: 65, G Loss: 1.4155, D Loss: 1.8363, mask loss: 1.1602, extra loss: 0.5105\n",
      "Epoch: 2, Step: 66, G Loss: 1.3944, D Loss: 1.8363, mask loss: 1.1360, extra loss: 0.5167\n",
      "Epoch: 2, Step: 67, G Loss: 1.4554, D Loss: 1.8363, mask loss: 1.1714, extra loss: 0.5679\n",
      "Epoch: 2, Step: 68, G Loss: 1.6604, D Loss: 1.8363, mask loss: 1.3897, extra loss: 0.5414\n",
      "Epoch: 2, Step: 69, G Loss: 1.4383, D Loss: 1.8363, mask loss: 1.1486, extra loss: 0.5792\n",
      "Epoch: 2, Step: 70, G Loss: 1.3525, D Loss: 1.8363, mask loss: 1.0882, extra loss: 0.5286\n",
      "Epoch: 2, Step: 71, G Loss: 1.5227, D Loss: 1.8545, mask loss: 1.2449, extra loss: 0.5557\n",
      "Epoch: 2, Step: 72, G Loss: 1.6084, D Loss: 1.8545, mask loss: 1.3480, extra loss: 0.5207\n",
      "Epoch: 2, Step: 73, G Loss: 1.5808, D Loss: 1.8545, mask loss: 1.3356, extra loss: 0.4903\n",
      "Epoch: 2, Step: 74, G Loss: 1.4964, D Loss: 1.8545, mask loss: 1.2539, extra loss: 0.4849\n",
      "Epoch: 2, Step: 75, G Loss: 1.5969, D Loss: 1.8545, mask loss: 1.3512, extra loss: 0.4914\n",
      "Epoch: 2, Step: 76, G Loss: 1.5369, D Loss: 1.8545, mask loss: 1.2828, extra loss: 0.5083\n",
      "Epoch: 2, Step: 77, G Loss: 1.7271, D Loss: 1.8545, mask loss: 1.4168, extra loss: 0.6204\n",
      "Epoch: 2, Step: 78, G Loss: 1.5043, D Loss: 1.8545, mask loss: 1.2664, extra loss: 0.4758\n",
      "Epoch: 2, Step: 79, G Loss: 1.4547, D Loss: 1.8545, mask loss: 1.2100, extra loss: 0.4894\n",
      "Epoch: 2, Step: 80, G Loss: 1.5460, D Loss: 1.8545, mask loss: 1.2642, extra loss: 0.5635\n",
      "Epoch: 2, Step: 81, G Loss: 1.4922, D Loss: 1.6606, mask loss: 1.1992, extra loss: 0.5860\n",
      "Epoch: 2, Step: 82, G Loss: 1.5002, D Loss: 1.6606, mask loss: 1.2001, extra loss: 0.6002\n",
      "Epoch: 2, Step: 83, G Loss: 1.4628, D Loss: 1.6606, mask loss: 1.1860, extra loss: 0.5536\n",
      "Epoch: 2, Step: 84, G Loss: 1.4014, D Loss: 1.6606, mask loss: 1.1173, extra loss: 0.5682\n",
      "Epoch: 2, Step: 85, G Loss: 1.4161, D Loss: 1.6606, mask loss: 1.1111, extra loss: 0.6101\n",
      "Epoch: 2, Step: 86, G Loss: 1.6106, D Loss: 1.6606, mask loss: 1.3403, extra loss: 0.5407\n",
      "Epoch: 2, Step: 87, G Loss: 1.3687, D Loss: 1.6606, mask loss: 1.0866, extra loss: 0.5643\n",
      "Epoch: 2, Step: 88, G Loss: 1.4151, D Loss: 1.6606, mask loss: 1.1378, extra loss: 0.5545\n",
      "Epoch: 2, Step: 89, G Loss: 1.6292, D Loss: 1.6606, mask loss: 1.3721, extra loss: 0.5142\n",
      "Epoch: 2, Step: 90, G Loss: 1.5084, D Loss: 1.6606, mask loss: 1.2346, extra loss: 0.5476\n",
      "Epoch: 2, Step: 91, G Loss: 1.5135, D Loss: 1.7472, mask loss: 1.2380, extra loss: 0.5511\n",
      "Epoch: 2, Step: 92, G Loss: 1.4671, D Loss: 1.7472, mask loss: 1.1932, extra loss: 0.5479\n",
      "Epoch: 2, Step: 93, G Loss: 1.5933, D Loss: 1.7472, mask loss: 1.3201, extra loss: 0.5462\n",
      "Epoch: 2, Step: 94, G Loss: 1.5186, D Loss: 1.7472, mask loss: 1.2291, extra loss: 0.5789\n",
      "Epoch: 2, Step: 95, G Loss: 1.4682, D Loss: 1.7472, mask loss: 1.1906, extra loss: 0.5552\n",
      "Epoch: 2, Step: 96, G Loss: 1.7587, D Loss: 1.7472, mask loss: 1.4760, extra loss: 0.5654\n",
      "Epoch: 2, Step: 97, G Loss: 1.5886, D Loss: 1.7472, mask loss: 1.2713, extra loss: 0.6344\n",
      "Epoch: 2, Step: 98, G Loss: 1.5240, D Loss: 1.7472, mask loss: 1.2129, extra loss: 0.6222\n",
      "Epoch: 2, Step: 99, G Loss: 1.3945, D Loss: 1.7472, mask loss: 1.0883, extra loss: 0.6124\n",
      "Epoch: 2, Step: 100, G Loss: 1.6324, D Loss: 1.7472, mask loss: 1.3341, extra loss: 0.5965\n",
      "Epoch: 2, Step: 101, G Loss: 1.5469, D Loss: 1.6407, mask loss: 1.2464, extra loss: 0.6009\n",
      "Epoch: 2, Step: 102, G Loss: 1.4769, D Loss: 1.6407, mask loss: 1.1717, extra loss: 0.6104\n",
      "Epoch: 2, Step: 103, G Loss: 1.4956, D Loss: 1.6407, mask loss: 1.1926, extra loss: 0.6059\n",
      "Epoch: 2, Step: 104, G Loss: 1.5115, D Loss: 1.6407, mask loss: 1.1951, extra loss: 0.6328\n",
      "Epoch: 2, Step: 105, G Loss: 1.5769, D Loss: 1.6407, mask loss: 1.2970, extra loss: 0.5597\n",
      "Epoch: 2, Step: 106, G Loss: 1.5539, D Loss: 1.6407, mask loss: 1.2658, extra loss: 0.5762\n",
      "Epoch: 2, Step: 107, G Loss: 1.5344, D Loss: 1.6407, mask loss: 1.2494, extra loss: 0.5700\n",
      "Epoch: 2, Step: 108, G Loss: 1.3973, D Loss: 1.6407, mask loss: 1.0934, extra loss: 0.6077\n",
      "Epoch: 2, Step: 109, G Loss: 1.4651, D Loss: 1.6407, mask loss: 1.1620, extra loss: 0.6063\n",
      "Epoch: 2, Step: 110, G Loss: 1.5101, D Loss: 1.6407, mask loss: 1.2155, extra loss: 0.5892\n",
      "Epoch: 2, Step: 111, G Loss: 1.6427, D Loss: 1.6021, mask loss: 1.3281, extra loss: 0.6293\n",
      "Epoch: 2, Step: 112, G Loss: 1.4554, D Loss: 1.6021, mask loss: 1.1486, extra loss: 0.6137\n",
      "Epoch: 2, Step: 113, G Loss: 1.3825, D Loss: 1.6021, mask loss: 1.0711, extra loss: 0.6227\n",
      "Epoch: 2, Step: 114, G Loss: 1.5875, D Loss: 1.6021, mask loss: 1.2699, extra loss: 0.6353\n",
      "Epoch: 2, Step: 115, G Loss: 1.2506, D Loss: 1.6021, mask loss: 0.9374, extra loss: 0.6263\n",
      "Epoch: 2, Step: 116, G Loss: 1.5222, D Loss: 1.6021, mask loss: 1.2011, extra loss: 0.6423\n",
      "Epoch: 2, Step: 117, G Loss: 1.4329, D Loss: 1.6021, mask loss: 1.1234, extra loss: 0.6189\n",
      "Epoch: 2, Step: 118, G Loss: 1.4522, D Loss: 1.6021, mask loss: 1.1658, extra loss: 0.5729\n",
      "Epoch: 2, Step: 119, G Loss: 1.6690, D Loss: 1.6021, mask loss: 1.3634, extra loss: 0.6112\n",
      "Epoch: 2, Step: 120, G Loss: 1.4418, D Loss: 1.6021, mask loss: 1.1364, extra loss: 0.6109\n",
      "Epoch: 2, Step: 121, G Loss: 1.5589, D Loss: 1.5772, mask loss: 1.2501, extra loss: 0.6176\n",
      "Epoch: 2, Step: 122, G Loss: 1.3946, D Loss: 1.5772, mask loss: 1.0870, extra loss: 0.6151\n",
      "Epoch: 2, Step: 123, G Loss: 1.5154, D Loss: 1.5772, mask loss: 1.2124, extra loss: 0.6059\n",
      "Epoch: 2, Step: 124, G Loss: 1.4997, D Loss: 1.5772, mask loss: 1.2027, extra loss: 0.5941\n",
      "Epoch: 2, Step: 125, G Loss: 1.4848, D Loss: 1.5772, mask loss: 1.1855, extra loss: 0.5987\n",
      "Epoch: 2, Step: 126, G Loss: 1.5293, D Loss: 1.5772, mask loss: 1.2178, extra loss: 0.6232\n",
      "Epoch: 2, Step: 127, G Loss: 1.6845, D Loss: 1.5772, mask loss: 1.3630, extra loss: 0.6430\n",
      "Epoch: 2, Step: 128, G Loss: 1.5350, D Loss: 1.5772, mask loss: 1.2140, extra loss: 0.6420\n",
      "Epoch: 2, Step: 129, G Loss: 1.3144, D Loss: 1.5772, mask loss: 1.0054, extra loss: 0.6180\n",
      "Epoch: 2, Step: 130, G Loss: 1.5786, D Loss: 1.5772, mask loss: 1.2522, extra loss: 0.6528\n",
      "Epoch: 2, Step: 131, G Loss: 1.6823, D Loss: 1.4728, mask loss: 1.3414, extra loss: 0.6817\n",
      "Epoch: 2, Step: 132, G Loss: 1.6216, D Loss: 1.4728, mask loss: 1.2901, extra loss: 0.6630\n",
      "Epoch: 2, Step: 133, G Loss: 1.4706, D Loss: 1.4728, mask loss: 1.1719, extra loss: 0.5974\n",
      "Epoch: 2, Step: 134, G Loss: 1.4665, D Loss: 1.4728, mask loss: 1.1644, extra loss: 0.6041\n",
      "Epoch: 2, Step: 135, G Loss: 1.6541, D Loss: 1.4728, mask loss: 1.3500, extra loss: 0.6083\n",
      "Epoch: 2, Step: 136, G Loss: 1.5764, D Loss: 1.4728, mask loss: 1.2634, extra loss: 0.6260\n",
      "Epoch: 2, Step: 137, G Loss: 1.4193, D Loss: 1.4728, mask loss: 1.1143, extra loss: 0.6099\n",
      "Epoch: 2, Step: 138, G Loss: 1.5436, D Loss: 1.4728, mask loss: 1.2394, extra loss: 0.6084\n",
      "Epoch: 2, Step: 139, G Loss: 1.4939, D Loss: 1.4728, mask loss: 1.1748, extra loss: 0.6382\n",
      "Epoch: 2, Step: 140, G Loss: 1.4371, D Loss: 1.4728, mask loss: 1.1315, extra loss: 0.6112\n",
      "Epoch: 2, Step: 141, G Loss: 1.5076, D Loss: 1.5108, mask loss: 1.1824, extra loss: 0.6505\n",
      "Epoch: 2, Step: 142, G Loss: 1.7020, D Loss: 1.5108, mask loss: 1.3913, extra loss: 0.6213\n",
      "Epoch: 2, Step: 143, G Loss: 1.5274, D Loss: 1.5108, mask loss: 1.2223, extra loss: 0.6102\n",
      "Epoch: 2, Step: 144, G Loss: 1.4405, D Loss: 1.5108, mask loss: 1.1256, extra loss: 0.6298\n",
      "Epoch: 2, Step: 145, G Loss: 1.3956, D Loss: 1.5108, mask loss: 1.0812, extra loss: 0.6288\n",
      "Epoch: 2, Step: 146, G Loss: 1.4600, D Loss: 1.5108, mask loss: 1.1410, extra loss: 0.6381\n",
      "Epoch: 2, Step: 147, G Loss: 1.3339, D Loss: 1.5108, mask loss: 1.0056, extra loss: 0.6566\n",
      "Epoch: 2, Step: 148, G Loss: 1.4739, D Loss: 1.5108, mask loss: 1.1436, extra loss: 0.6607\n",
      "Epoch: 2, Step: 149, G Loss: 1.5696, D Loss: 1.5108, mask loss: 1.2544, extra loss: 0.6303\n",
      "Epoch: 2, Step: 150, G Loss: 1.4330, D Loss: 1.5108, mask loss: 1.1079, extra loss: 0.6503\n",
      "Epoch: 2, Step: 151, G Loss: 1.6045, D Loss: 1.4442, mask loss: 1.2799, extra loss: 0.6493\n",
      "Epoch: 2, Step: 152, G Loss: 1.5866, D Loss: 1.4442, mask loss: 1.2509, extra loss: 0.6714\n",
      "Epoch: 2, Step: 153, G Loss: 1.3408, D Loss: 1.4442, mask loss: 0.9991, extra loss: 0.6835\n",
      "Epoch: 2, Step: 154, G Loss: 1.6390, D Loss: 1.4442, mask loss: 1.2899, extra loss: 0.6982\n",
      "Epoch: 2, Step: 155, G Loss: 1.4722, D Loss: 1.4442, mask loss: 1.1358, extra loss: 0.6727\n",
      "Epoch: 2, Step: 156, G Loss: 1.5437, D Loss: 1.4442, mask loss: 1.2257, extra loss: 0.6360\n",
      "Epoch: 2, Step: 157, G Loss: 1.5106, D Loss: 1.4442, mask loss: 1.1938, extra loss: 0.6338\n",
      "Epoch: 2, Step: 158, G Loss: 1.4249, D Loss: 1.4442, mask loss: 1.1113, extra loss: 0.6272\n",
      "Epoch: 2, Step: 159, G Loss: 1.5179, D Loss: 1.4442, mask loss: 1.1979, extra loss: 0.6400\n",
      "Epoch: 2, Step: 160, G Loss: 1.4430, D Loss: 1.4442, mask loss: 1.1334, extra loss: 0.6192\n",
      "Epoch: 2, Step: 161, G Loss: 1.5843, D Loss: 1.4539, mask loss: 1.2495, extra loss: 0.6696\n",
      "Epoch: 2, Step: 162, G Loss: 1.5066, D Loss: 1.4539, mask loss: 1.1826, extra loss: 0.6480\n",
      "Epoch: 2, Step: 163, G Loss: 1.5385, D Loss: 1.4539, mask loss: 1.2240, extra loss: 0.6291\n",
      "Epoch: 2, Step: 164, G Loss: 1.3590, D Loss: 1.4539, mask loss: 1.0276, extra loss: 0.6627\n",
      "Epoch: 2, Step: 165, G Loss: 1.6918, D Loss: 1.4539, mask loss: 1.3599, extra loss: 0.6639\n",
      "Epoch: 2, Step: 166, G Loss: 1.5775, D Loss: 1.4539, mask loss: 1.2522, extra loss: 0.6505\n",
      "Epoch: 2, Step: 167, G Loss: 1.4488, D Loss: 1.4539, mask loss: 1.1458, extra loss: 0.6059\n",
      "Epoch: 2, Step: 168, G Loss: 1.5380, D Loss: 1.4539, mask loss: 1.2269, extra loss: 0.6222\n",
      "Epoch: 2, Step: 169, G Loss: 1.3404, D Loss: 1.4539, mask loss: 1.0240, extra loss: 0.6330\n",
      "Epoch: 2, Step: 170, G Loss: 1.5546, D Loss: 1.4539, mask loss: 1.2419, extra loss: 0.6254\n",
      "Epoch: 2, Step: 171, G Loss: 1.3687, D Loss: 1.4674, mask loss: 1.0345, extra loss: 0.6684\n",
      "Epoch: 2, Step: 172, G Loss: 1.6964, D Loss: 1.4674, mask loss: 1.3379, extra loss: 0.7171\n",
      "Epoch: 2, Step: 173, G Loss: 1.5593, D Loss: 1.4674, mask loss: 1.2340, extra loss: 0.6506\n",
      "Epoch: 2, Step: 174, G Loss: 1.3785, D Loss: 1.4674, mask loss: 1.0508, extra loss: 0.6554\n",
      "Epoch: 2, Step: 175, G Loss: 1.4002, D Loss: 1.4674, mask loss: 1.0845, extra loss: 0.6314\n",
      "Epoch: 2, Step: 176, G Loss: 1.5299, D Loss: 1.4674, mask loss: 1.2142, extra loss: 0.6315\n",
      "Epoch: 2, Step: 177, G Loss: 1.5295, D Loss: 1.4674, mask loss: 1.2058, extra loss: 0.6475\n",
      "Epoch: 2, Step: 178, G Loss: 1.5064, D Loss: 1.4674, mask loss: 1.1988, extra loss: 0.6152\n",
      "Epoch: 2, Step: 179, G Loss: 1.3251, D Loss: 1.4674, mask loss: 1.0023, extra loss: 0.6455\n",
      "Epoch: 2, Step: 180, G Loss: 1.7351, D Loss: 1.4674, mask loss: 1.3927, extra loss: 0.6848\n",
      "Epoch: 2, Step: 181, G Loss: 1.4595, D Loss: 1.5063, mask loss: 1.1221, extra loss: 0.6748\n",
      "Epoch: 2, Step: 182, G Loss: 1.4907, D Loss: 1.5063, mask loss: 1.1719, extra loss: 0.6376\n",
      "Epoch: 2, Step: 183, G Loss: 1.4939, D Loss: 1.5063, mask loss: 1.1458, extra loss: 0.6962\n",
      "Epoch: 2, Step: 184, G Loss: 1.4821, D Loss: 1.5063, mask loss: 1.1359, extra loss: 0.6924\n",
      "Epoch: 2, Step: 185, G Loss: 1.6053, D Loss: 1.5063, mask loss: 1.2428, extra loss: 0.7249\n",
      "Epoch: 2, Step: 186, G Loss: 1.4199, D Loss: 1.5063, mask loss: 1.0562, extra loss: 0.7273\n",
      "Epoch: 2, Step: 187, G Loss: 1.5612, D Loss: 1.5063, mask loss: 1.2365, extra loss: 0.6495\n",
      "Epoch: 2, Step: 188, G Loss: 1.5262, D Loss: 1.5063, mask loss: 1.1885, extra loss: 0.6756\n",
      "Epoch: 2, Step: 189, G Loss: 1.4294, D Loss: 1.5063, mask loss: 1.1020, extra loss: 0.6547\n",
      "Epoch: 2, Step: 190, G Loss: 1.7341, D Loss: 1.5063, mask loss: 1.4029, extra loss: 0.6622\n",
      "Epoch: 2, Step: 191, G Loss: 1.4408, D Loss: 1.4368, mask loss: 1.1203, extra loss: 0.6410\n",
      "Epoch: 2, Step: 192, G Loss: 1.5160, D Loss: 1.4368, mask loss: 1.1884, extra loss: 0.6552\n",
      "Epoch: 2, Step: 193, G Loss: 1.6467, D Loss: 1.4368, mask loss: 1.3260, extra loss: 0.6413\n",
      "Epoch: 2, Step: 194, G Loss: 1.5999, D Loss: 1.4368, mask loss: 1.2600, extra loss: 0.6799\n",
      "Epoch: 2, Step: 195, G Loss: 1.4832, D Loss: 1.4368, mask loss: 1.1603, extra loss: 0.6457\n",
      "Epoch: 2, Step: 196, G Loss: 1.4222, D Loss: 1.4368, mask loss: 1.0879, extra loss: 0.6685\n",
      "Epoch: 2, Step: 197, G Loss: 1.5438, D Loss: 1.4368, mask loss: 1.2099, extra loss: 0.6679\n",
      "Epoch: 2, Step: 198, G Loss: 1.4886, D Loss: 1.4368, mask loss: 1.1838, extra loss: 0.6096\n",
      "Epoch: 2, Step: 199, G Loss: 1.3446, D Loss: 1.4368, mask loss: 1.0539, extra loss: 0.5813\n",
      "Epoch: 2, Step: 200, G Loss: 1.4007, D Loss: 1.4368, mask loss: 1.0879, extra loss: 0.6257\n",
      "Epoch: 2, Step: 201, G Loss: 1.5759, D Loss: 1.5288, mask loss: 1.2825, extra loss: 0.5868\n",
      "Epoch: 2, Step: 202, G Loss: 1.4300, D Loss: 1.5288, mask loss: 1.1010, extra loss: 0.6580\n",
      "Epoch: 2, Step: 203, G Loss: 1.3978, D Loss: 1.5288, mask loss: 1.1117, extra loss: 0.5723\n",
      "Epoch: 2, Step: 204, G Loss: 1.3908, D Loss: 1.5288, mask loss: 1.0617, extra loss: 0.6581\n",
      "Epoch: 2, Step: 205, G Loss: 1.6622, D Loss: 1.5288, mask loss: 1.3359, extra loss: 0.6526\n",
      "Epoch: 2, Step: 206, G Loss: 1.3958, D Loss: 1.5288, mask loss: 1.0759, extra loss: 0.6397\n",
      "Epoch: 2, Step: 207, G Loss: 1.4107, D Loss: 1.5288, mask loss: 1.0938, extra loss: 0.6337\n",
      "Epoch: 2, Step: 208, G Loss: 1.4427, D Loss: 1.5288, mask loss: 1.1367, extra loss: 0.6120\n",
      "Epoch: 2, Step: 209, G Loss: 1.3387, D Loss: 1.5288, mask loss: 1.0454, extra loss: 0.5867\n",
      "Epoch: 2, Step: 210, G Loss: 1.3544, D Loss: 1.5288, mask loss: 1.0301, extra loss: 0.6487\n",
      "Epoch: 2, Step: 211, G Loss: 1.5846, D Loss: 1.4636, mask loss: 1.2755, extra loss: 0.6182\n",
      "Epoch: 2, Step: 212, G Loss: 1.3696, D Loss: 1.4636, mask loss: 1.0454, extra loss: 0.6483\n",
      "Epoch: 2, Step: 213, G Loss: 1.4657, D Loss: 1.4636, mask loss: 1.1583, extra loss: 0.6149\n",
      "Epoch: 2, Step: 214, G Loss: 1.4655, D Loss: 1.4636, mask loss: 1.1494, extra loss: 0.6322\n",
      "Epoch: 2, Step: 215, G Loss: 1.5570, D Loss: 1.4636, mask loss: 1.2174, extra loss: 0.6791\n",
      "Epoch: 2, Step: 216, G Loss: 1.4179, D Loss: 1.4636, mask loss: 1.0865, extra loss: 0.6629\n",
      "Epoch: 2, Step: 217, G Loss: 1.5738, D Loss: 1.4636, mask loss: 1.2401, extra loss: 0.6674\n",
      "Epoch: 2, Step: 218, G Loss: 1.5908, D Loss: 1.4636, mask loss: 1.2609, extra loss: 0.6599\n",
      "Epoch: 2, Step: 219, G Loss: 1.4589, D Loss: 1.4636, mask loss: 1.1290, extra loss: 0.6598\n",
      "Epoch: 2, Step: 220, G Loss: 1.4559, D Loss: 1.4636, mask loss: 1.1416, extra loss: 0.6287\n",
      "Epoch: 2, Step: 221, G Loss: 1.2890, D Loss: 1.5333, mask loss: 0.9691, extra loss: 0.6398\n",
      "Epoch: 2, Step: 222, G Loss: 1.3823, D Loss: 1.5333, mask loss: 1.0518, extra loss: 0.6609\n",
      "Epoch: 2, Step: 223, G Loss: 1.5274, D Loss: 1.5333, mask loss: 1.1986, extra loss: 0.6575\n",
      "Epoch: 2, Step: 224, G Loss: 1.4711, D Loss: 1.5333, mask loss: 1.1731, extra loss: 0.5961\n",
      "Epoch: 2, Step: 225, G Loss: 1.3554, D Loss: 1.5333, mask loss: 1.0242, extra loss: 0.6623\n",
      "Epoch: 2, Step: 226, G Loss: 1.4647, D Loss: 1.5333, mask loss: 1.1381, extra loss: 0.6533\n",
      "Epoch: 2, Step: 227, G Loss: 1.4823, D Loss: 1.5333, mask loss: 1.1450, extra loss: 0.6746\n",
      "Epoch: 2, Step: 228, G Loss: 1.3157, D Loss: 1.5333, mask loss: 0.9804, extra loss: 0.6706\n",
      "Epoch: 2, Step: 229, G Loss: 1.6109, D Loss: 1.5333, mask loss: 1.3049, extra loss: 0.6120\n",
      "Epoch: 2, Step: 230, G Loss: 1.6175, D Loss: 1.5333, mask loss: 1.3076, extra loss: 0.6200\n",
      "Epoch: 2, Step: 231, G Loss: 1.4318, D Loss: 1.4229, mask loss: 1.1104, extra loss: 0.6427\n",
      "Epoch: 2, Step: 232, G Loss: 1.5263, D Loss: 1.4229, mask loss: 1.1878, extra loss: 0.6770\n",
      "Epoch: 2, Step: 233, G Loss: 1.5097, D Loss: 1.4229, mask loss: 1.1946, extra loss: 0.6302\n",
      "Epoch: 2, Step: 234, G Loss: 1.5131, D Loss: 1.4229, mask loss: 1.1799, extra loss: 0.6664\n",
      "Epoch: 2, Step: 235, G Loss: 1.2691, D Loss: 1.4229, mask loss: 0.9476, extra loss: 0.6431\n",
      "Epoch: 2, Step: 236, G Loss: 1.3887, D Loss: 1.4229, mask loss: 1.0730, extra loss: 0.6313\n",
      "Epoch: 2, Step: 237, G Loss: 1.4966, D Loss: 1.4229, mask loss: 1.1845, extra loss: 0.6241\n",
      "Epoch: 2, Step: 238, G Loss: 1.2629, D Loss: 1.4229, mask loss: 0.9513, extra loss: 0.6233\n",
      "Epoch: 2, Step: 239, G Loss: 1.4331, D Loss: 1.4229, mask loss: 1.0909, extra loss: 0.6845\n",
      "Epoch: 2, Step: 240, G Loss: 1.4828, D Loss: 1.4229, mask loss: 1.1558, extra loss: 0.6540\n",
      "Epoch: 2, Step: 241, G Loss: 1.3574, D Loss: 1.4277, mask loss: 1.0444, extra loss: 0.6261\n",
      "Epoch: 2, Step: 242, G Loss: 1.4564, D Loss: 1.4277, mask loss: 1.1022, extra loss: 0.7085\n",
      "Epoch: 2, Step: 243, G Loss: 1.5434, D Loss: 1.4277, mask loss: 1.2050, extra loss: 0.6767\n",
      "Epoch: 2, Step: 244, G Loss: 1.4706, D Loss: 1.4277, mask loss: 1.1628, extra loss: 0.6156\n",
      "Epoch: 2, Step: 245, G Loss: 1.3756, D Loss: 1.4277, mask loss: 1.0317, extra loss: 0.6877\n",
      "Epoch: 2, Step: 246, G Loss: 1.3043, D Loss: 1.4277, mask loss: 1.0058, extra loss: 0.5970\n",
      "Epoch: 2, Step: 247, G Loss: 1.6642, D Loss: 1.4277, mask loss: 1.3496, extra loss: 0.6293\n",
      "Epoch: 2, Step: 248, G Loss: 1.3777, D Loss: 1.4277, mask loss: 1.0764, extra loss: 0.6026\n",
      "Epoch: 2, Step: 249, G Loss: 1.4092, D Loss: 1.4277, mask loss: 1.0825, extra loss: 0.6536\n",
      "Epoch: 2, Step: 250, G Loss: 1.2064, D Loss: 1.4277, mask loss: 0.8938, extra loss: 0.6253\n",
      "Epoch: 2, Step: 251, G Loss: 1.3516, D Loss: 1.5016, mask loss: 1.0362, extra loss: 0.6308\n",
      "Epoch: 2, Step: 252, G Loss: 1.4181, D Loss: 1.5016, mask loss: 1.1149, extra loss: 0.6063\n",
      "Epoch: 2, Step: 253, G Loss: 1.5359, D Loss: 1.5016, mask loss: 1.2268, extra loss: 0.6181\n",
      "Epoch: 2, Step: 254, G Loss: 1.3392, D Loss: 1.5016, mask loss: 0.9839, extra loss: 0.7107\n",
      "Epoch: 2, Step: 255, G Loss: 1.4435, D Loss: 1.5016, mask loss: 1.1228, extra loss: 0.6415\n",
      "Epoch: 2, Step: 256, G Loss: 1.5553, D Loss: 1.5016, mask loss: 1.2281, extra loss: 0.6545\n",
      "Epoch: 2, Step: 257, G Loss: 1.4666, D Loss: 1.5016, mask loss: 1.1535, extra loss: 0.6261\n",
      "Epoch: 2, Step: 258, G Loss: 1.4625, D Loss: 1.5016, mask loss: 1.1588, extra loss: 0.6074\n",
      "Epoch: 2, Step: 259, G Loss: 1.3344, D Loss: 1.5016, mask loss: 1.0101, extra loss: 0.6488\n",
      "Epoch: 2, Step: 260, G Loss: 1.3926, D Loss: 1.5016, mask loss: 1.1157, extra loss: 0.5538\n",
      "Epoch: 2, Step: 261, G Loss: 1.4265, D Loss: 1.4933, mask loss: 1.0908, extra loss: 0.6713\n",
      "Epoch: 2, Step: 262, G Loss: 1.2122, D Loss: 1.4933, mask loss: 0.9101, extra loss: 0.6043\n",
      "Epoch: 2, Step: 263, G Loss: 1.5132, D Loss: 1.4933, mask loss: 1.1913, extra loss: 0.6438\n",
      "Epoch: 2, Step: 264, G Loss: 1.4901, D Loss: 1.4933, mask loss: 1.1742, extra loss: 0.6318\n",
      "Epoch: 2, Step: 265, G Loss: 1.2042, D Loss: 1.4933, mask loss: 0.9025, extra loss: 0.6034\n",
      "Epoch: 2, Step: 266, G Loss: 1.6826, D Loss: 1.4933, mask loss: 1.3797, extra loss: 0.6058\n",
      "Epoch: 2, Step: 267, G Loss: 1.4849, D Loss: 1.4933, mask loss: 1.1551, extra loss: 0.6595\n",
      "Epoch: 2, Step: 268, G Loss: 1.4239, D Loss: 1.4933, mask loss: 1.1028, extra loss: 0.6423\n",
      "Epoch: 2, Step: 269, G Loss: 1.4878, D Loss: 1.4933, mask loss: 1.1620, extra loss: 0.6517\n",
      "Epoch: 2, Step: 270, G Loss: 1.5903, D Loss: 1.4933, mask loss: 1.2686, extra loss: 0.6434\n",
      "Epoch: 2, Step: 271, G Loss: 1.3890, D Loss: 1.4811, mask loss: 1.0646, extra loss: 0.6488\n",
      "Epoch: 2, Step: 272, G Loss: 1.5252, D Loss: 1.4811, mask loss: 1.1927, extra loss: 0.6650\n",
      "Epoch: 2, Step: 273, G Loss: 1.3443, D Loss: 1.4811, mask loss: 1.0333, extra loss: 0.6221\n",
      "Epoch: 2, Step: 274, G Loss: 1.3663, D Loss: 1.4811, mask loss: 1.0648, extra loss: 0.6030\n",
      "Epoch: 2, Step: 275, G Loss: 1.3279, D Loss: 1.4811, mask loss: 1.0084, extra loss: 0.6392\n",
      "Epoch: 2, Step: 276, G Loss: 1.4848, D Loss: 1.4811, mask loss: 1.1843, extra loss: 0.6008\n",
      "Epoch: 2, Step: 277, G Loss: 1.3569, D Loss: 1.4811, mask loss: 1.0358, extra loss: 0.6422\n",
      "Epoch: 2, Step: 278, G Loss: 1.3422, D Loss: 1.4811, mask loss: 1.0625, extra loss: 0.5595\n",
      "Epoch: 2, Step: 279, G Loss: 1.4570, D Loss: 1.4811, mask loss: 1.1566, extra loss: 0.6009\n",
      "Epoch: 2, Step: 280, G Loss: 1.5726, D Loss: 1.4811, mask loss: 1.2999, extra loss: 0.5454\n",
      "Epoch: 2, Step: 281, G Loss: 1.3359, D Loss: 1.5829, mask loss: 1.0212, extra loss: 0.6295\n",
      "Epoch: 2, Step: 282, G Loss: 1.3964, D Loss: 1.5829, mask loss: 1.1030, extra loss: 0.5868\n",
      "Epoch: 2, Step: 283, G Loss: 1.3423, D Loss: 1.5829, mask loss: 1.0102, extra loss: 0.6642\n",
      "Epoch: 2, Step: 284, G Loss: 1.5753, D Loss: 1.5829, mask loss: 1.2529, extra loss: 0.6448\n",
      "Epoch: 2, Step: 285, G Loss: 1.3883, D Loss: 1.5829, mask loss: 1.0707, extra loss: 0.6352\n",
      "Epoch: 2, Step: 286, G Loss: 1.3947, D Loss: 1.5829, mask loss: 1.0627, extra loss: 0.6640\n",
      "Epoch: 2, Step: 287, G Loss: 1.4714, D Loss: 1.5829, mask loss: 1.1607, extra loss: 0.6214\n",
      "Epoch: 2, Step: 288, G Loss: 1.5498, D Loss: 1.5829, mask loss: 1.2320, extra loss: 0.6356\n",
      "Epoch: 2, Step: 289, G Loss: 1.4981, D Loss: 1.5829, mask loss: 1.1999, extra loss: 0.5964\n",
      "Epoch: 2, Step: 290, G Loss: 1.4258, D Loss: 1.5829, mask loss: 1.1389, extra loss: 0.5738\n",
      "Epoch: 2, Step: 291, G Loss: 1.2964, D Loss: 1.6086, mask loss: 1.0350, extra loss: 0.5229\n",
      "Epoch: 2, Step: 292, G Loss: 1.4244, D Loss: 1.6086, mask loss: 1.1290, extra loss: 0.5908\n",
      "Epoch: 2, Step: 293, G Loss: 1.4126, D Loss: 1.6086, mask loss: 1.1336, extra loss: 0.5582\n",
      "Epoch: 2, Step: 294, G Loss: 1.4684, D Loss: 1.6086, mask loss: 1.1907, extra loss: 0.5555\n",
      "Epoch: 2, Step: 295, G Loss: 1.3789, D Loss: 1.6086, mask loss: 1.1057, extra loss: 0.5464\n",
      "Epoch: 2, Step: 296, G Loss: 1.3281, D Loss: 1.6086, mask loss: 1.0422, extra loss: 0.5718\n",
      "Epoch: 2, Step: 297, G Loss: 1.5562, D Loss: 1.6086, mask loss: 1.2839, extra loss: 0.5447\n",
      "Epoch: 2, Step: 298, G Loss: 1.3824, D Loss: 1.6086, mask loss: 1.1038, extra loss: 0.5571\n",
      "Epoch: 2, Step: 299, G Loss: 1.3920, D Loss: 1.6086, mask loss: 1.1206, extra loss: 0.5429\n",
      "Epoch: 2, Step: 300, G Loss: 1.4686, D Loss: 1.6086, mask loss: 1.1866, extra loss: 0.5639\n",
      "Epoch: 2, Step: 301, G Loss: 1.5313, D Loss: 1.5643, mask loss: 1.1949, extra loss: 0.6729\n",
      "Epoch: 2, Step: 302, G Loss: 1.4904, D Loss: 1.5643, mask loss: 1.1692, extra loss: 0.6424\n",
      "Epoch: 2, Step: 303, G Loss: 1.3492, D Loss: 1.5643, mask loss: 1.0477, extra loss: 0.6030\n",
      "Epoch: 2, Step: 304, G Loss: 1.6536, D Loss: 1.5643, mask loss: 1.3828, extra loss: 0.5415\n",
      "Epoch: 2, G Loss: 1.5123(Mask Loss: 1.1958, Extra Loss: 0.6331), D Loss: 1.6146, Train FID: 237.6711, Val FID: 248.4909\n",
      "Epoch: 3, Step: 1, G Loss: 1.4249, D Loss: 1.6009, mask loss: 1.1002, extra loss: 0.6494\n",
      "Epoch: 3, Step: 2, G Loss: 1.5565, D Loss: 1.6009, mask loss: 1.2386, extra loss: 0.6357\n",
      "Epoch: 3, Step: 3, G Loss: 1.3973, D Loss: 1.6009, mask loss: 1.0835, extra loss: 0.6275\n",
      "Epoch: 3, Step: 4, G Loss: 1.4551, D Loss: 1.6009, mask loss: 1.1333, extra loss: 0.6436\n",
      "Epoch: 3, Step: 5, G Loss: 1.6074, D Loss: 1.6009, mask loss: 1.2994, extra loss: 0.6159\n",
      "Epoch: 3, Step: 6, G Loss: 1.3236, D Loss: 1.6009, mask loss: 0.9935, extra loss: 0.6602\n",
      "Epoch: 3, Step: 7, G Loss: 1.2976, D Loss: 1.6009, mask loss: 0.9683, extra loss: 0.6586\n",
      "Epoch: 3, Step: 8, G Loss: 1.5237, D Loss: 1.6009, mask loss: 1.2012, extra loss: 0.6450\n",
      "Epoch: 3, Step: 9, G Loss: 1.2818, D Loss: 1.6009, mask loss: 0.9419, extra loss: 0.6799\n",
      "Epoch: 3, Step: 10, G Loss: 1.4436, D Loss: 1.6009, mask loss: 1.0965, extra loss: 0.6942\n",
      "Epoch: 3, Step: 11, G Loss: 1.4837, D Loss: 1.4726, mask loss: 1.1318, extra loss: 0.7038\n",
      "Epoch: 3, Step: 12, G Loss: 1.5137, D Loss: 1.4726, mask loss: 1.1531, extra loss: 0.7213\n",
      "Epoch: 3, Step: 13, G Loss: 1.5237, D Loss: 1.4726, mask loss: 1.1798, extra loss: 0.6877\n",
      "Epoch: 3, Step: 14, G Loss: 1.6014, D Loss: 1.4726, mask loss: 1.2170, extra loss: 0.7689\n",
      "Epoch: 3, Step: 15, G Loss: 1.4713, D Loss: 1.4726, mask loss: 1.1309, extra loss: 0.6808\n",
      "Epoch: 3, Step: 16, G Loss: 1.5289, D Loss: 1.4726, mask loss: 1.1869, extra loss: 0.6841\n",
      "Epoch: 3, Step: 17, G Loss: 1.3139, D Loss: 1.4726, mask loss: 0.9843, extra loss: 0.6592\n",
      "Epoch: 3, Step: 18, G Loss: 1.7534, D Loss: 1.4726, mask loss: 1.4138, extra loss: 0.6791\n",
      "Epoch: 3, Step: 19, G Loss: 1.4275, D Loss: 1.4726, mask loss: 1.1011, extra loss: 0.6528\n",
      "Epoch: 3, Step: 20, G Loss: 1.2662, D Loss: 1.4726, mask loss: 0.9100, extra loss: 0.7123\n",
      "Epoch: 3, Step: 21, G Loss: 1.4940, D Loss: 1.5490, mask loss: 1.1187, extra loss: 0.7507\n",
      "Epoch: 3, Step: 22, G Loss: 1.4557, D Loss: 1.5490, mask loss: 1.1092, extra loss: 0.6930\n",
      "Epoch: 3, Step: 23, G Loss: 1.5765, D Loss: 1.5490, mask loss: 1.1807, extra loss: 0.7915\n",
      "Epoch: 3, Step: 24, G Loss: 1.5075, D Loss: 1.5490, mask loss: 1.1114, extra loss: 0.7922\n",
      "Epoch: 3, Step: 25, G Loss: 1.6045, D Loss: 1.5490, mask loss: 1.2310, extra loss: 0.7469\n",
      "Epoch: 3, Step: 26, G Loss: 1.6316, D Loss: 1.5490, mask loss: 1.2475, extra loss: 0.7681\n",
      "Epoch: 3, Step: 27, G Loss: 1.6208, D Loss: 1.5490, mask loss: 1.2583, extra loss: 0.7248\n",
      "Epoch: 3, Step: 28, G Loss: 1.6334, D Loss: 1.5490, mask loss: 1.2710, extra loss: 0.7249\n",
      "Epoch: 3, Step: 29, G Loss: 1.4082, D Loss: 1.5490, mask loss: 1.0560, extra loss: 0.7043\n",
      "Epoch: 3, Step: 30, G Loss: 1.6081, D Loss: 1.5490, mask loss: 1.2348, extra loss: 0.7466\n",
      "Epoch: 3, Step: 31, G Loss: 1.4578, D Loss: 1.4881, mask loss: 1.1094, extra loss: 0.6968\n",
      "Epoch: 3, Step: 32, G Loss: 1.6335, D Loss: 1.4881, mask loss: 1.2618, extra loss: 0.7435\n",
      "Epoch: 3, Step: 33, G Loss: 1.5371, D Loss: 1.4881, mask loss: 1.1866, extra loss: 0.7009\n",
      "Epoch: 3, Step: 34, G Loss: 1.4724, D Loss: 1.4881, mask loss: 1.0943, extra loss: 0.7563\n",
      "Epoch: 3, Step: 35, G Loss: 1.6950, D Loss: 1.4881, mask loss: 1.3467, extra loss: 0.6967\n",
      "Epoch: 3, Step: 36, G Loss: 1.3972, D Loss: 1.4881, mask loss: 1.0543, extra loss: 0.6860\n",
      "Epoch: 3, Step: 37, G Loss: 1.4414, D Loss: 1.4881, mask loss: 1.0931, extra loss: 0.6966\n",
      "Epoch: 3, Step: 38, G Loss: 1.4340, D Loss: 1.4881, mask loss: 1.0859, extra loss: 0.6961\n",
      "Epoch: 3, Step: 39, G Loss: 1.3778, D Loss: 1.4881, mask loss: 1.0281, extra loss: 0.6995\n",
      "Epoch: 3, Step: 40, G Loss: 1.4491, D Loss: 1.4881, mask loss: 1.1017, extra loss: 0.6948\n",
      "Epoch: 3, Step: 41, G Loss: 1.3742, D Loss: 1.4699, mask loss: 1.0485, extra loss: 0.6515\n",
      "Epoch: 3, Step: 42, G Loss: 1.4228, D Loss: 1.4699, mask loss: 1.0846, extra loss: 0.6765\n",
      "Epoch: 3, Step: 43, G Loss: 1.2400, D Loss: 1.4699, mask loss: 0.9083, extra loss: 0.6635\n",
      "Epoch: 3, Step: 44, G Loss: 1.3766, D Loss: 1.4699, mask loss: 1.0182, extra loss: 0.7169\n",
      "Epoch: 3, Step: 45, G Loss: 1.5264, D Loss: 1.4699, mask loss: 1.1866, extra loss: 0.6796\n",
      "Epoch: 3, Step: 46, G Loss: 1.5123, D Loss: 1.4699, mask loss: 1.1866, extra loss: 0.6515\n",
      "Epoch: 3, Step: 47, G Loss: 1.6790, D Loss: 1.4699, mask loss: 1.3586, extra loss: 0.6408\n",
      "Epoch: 3, Step: 48, G Loss: 1.4176, D Loss: 1.4699, mask loss: 1.1075, extra loss: 0.6202\n",
      "Epoch: 3, Step: 49, G Loss: 1.3556, D Loss: 1.4699, mask loss: 1.0365, extra loss: 0.6383\n",
      "Epoch: 3, Step: 50, G Loss: 1.2985, D Loss: 1.4699, mask loss: 0.9546, extra loss: 0.6878\n",
      "Epoch: 3, Step: 51, G Loss: 1.3146, D Loss: 1.4884, mask loss: 0.9856, extra loss: 0.6579\n",
      "Epoch: 3, Step: 52, G Loss: 1.2838, D Loss: 1.4884, mask loss: 0.9722, extra loss: 0.6231\n",
      "Epoch: 3, Step: 53, G Loss: 1.2145, D Loss: 1.4884, mask loss: 0.8967, extra loss: 0.6358\n",
      "Epoch: 3, Step: 54, G Loss: 1.3630, D Loss: 1.4884, mask loss: 1.0339, extra loss: 0.6582\n",
      "Epoch: 3, Step: 55, G Loss: 1.4402, D Loss: 1.4884, mask loss: 1.1356, extra loss: 0.6093\n",
      "Epoch: 3, Step: 56, G Loss: 1.3917, D Loss: 1.4884, mask loss: 1.0632, extra loss: 0.6571\n",
      "Epoch: 3, Step: 57, G Loss: 1.3548, D Loss: 1.4884, mask loss: 1.0711, extra loss: 0.5675\n",
      "Epoch: 3, Step: 58, G Loss: 1.4739, D Loss: 1.4884, mask loss: 1.1527, extra loss: 0.6422\n",
      "Epoch: 3, Step: 59, G Loss: 1.3895, D Loss: 1.4884, mask loss: 1.0646, extra loss: 0.6499\n",
      "Epoch: 3, Step: 60, G Loss: 1.4360, D Loss: 1.4884, mask loss: 1.1159, extra loss: 0.6403\n",
      "Epoch: 3, Step: 61, G Loss: 1.2984, D Loss: 1.5108, mask loss: 0.9740, extra loss: 0.6488\n",
      "Epoch: 3, Step: 62, G Loss: 1.3745, D Loss: 1.5108, mask loss: 1.0566, extra loss: 0.6358\n",
      "Epoch: 3, Step: 63, G Loss: 1.3664, D Loss: 1.5108, mask loss: 1.0477, extra loss: 0.6373\n",
      "Epoch: 3, Step: 64, G Loss: 1.3163, D Loss: 1.5108, mask loss: 1.0091, extra loss: 0.6145\n",
      "Epoch: 3, Step: 65, G Loss: 1.3283, D Loss: 1.5108, mask loss: 1.0388, extra loss: 0.5791\n",
      "Epoch: 3, Step: 66, G Loss: 1.3213, D Loss: 1.5108, mask loss: 0.9960, extra loss: 0.6507\n",
      "Epoch: 3, Step: 67, G Loss: 1.2213, D Loss: 1.5108, mask loss: 0.9128, extra loss: 0.6169\n",
      "Epoch: 3, Step: 68, G Loss: 1.4648, D Loss: 1.5108, mask loss: 1.1432, extra loss: 0.6431\n",
      "Epoch: 3, Step: 69, G Loss: 1.3365, D Loss: 1.5108, mask loss: 1.0187, extra loss: 0.6355\n",
      "Epoch: 3, Step: 70, G Loss: 1.5954, D Loss: 1.5108, mask loss: 1.3035, extra loss: 0.5837\n",
      "Epoch: 3, Step: 71, G Loss: 1.5079, D Loss: 1.4827, mask loss: 1.1932, extra loss: 0.6295\n",
      "Epoch: 3, Step: 72, G Loss: 1.2939, D Loss: 1.4827, mask loss: 0.9612, extra loss: 0.6654\n",
      "Epoch: 3, Step: 73, G Loss: 1.4592, D Loss: 1.4827, mask loss: 1.1333, extra loss: 0.6517\n",
      "Epoch: 3, Step: 74, G Loss: 1.4318, D Loss: 1.4827, mask loss: 1.1168, extra loss: 0.6300\n",
      "Epoch: 3, Step: 75, G Loss: 1.2295, D Loss: 1.4827, mask loss: 0.9097, extra loss: 0.6398\n",
      "Epoch: 3, Step: 76, G Loss: 1.5131, D Loss: 1.4827, mask loss: 1.2002, extra loss: 0.6259\n",
      "Epoch: 3, Step: 77, G Loss: 1.6606, D Loss: 1.4827, mask loss: 1.3530, extra loss: 0.6151\n",
      "Epoch: 3, Step: 78, G Loss: 1.5540, D Loss: 1.4827, mask loss: 1.2574, extra loss: 0.5933\n",
      "Epoch: 3, Step: 79, G Loss: 1.5812, D Loss: 1.4827, mask loss: 1.2818, extra loss: 0.5988\n",
      "Epoch: 3, Step: 80, G Loss: 1.4835, D Loss: 1.4827, mask loss: 1.1908, extra loss: 0.5853\n",
      "Epoch: 3, Step: 81, G Loss: 1.5318, D Loss: 1.5005, mask loss: 1.2094, extra loss: 0.6449\n",
      "Epoch: 3, Step: 82, G Loss: 1.4531, D Loss: 1.5005, mask loss: 1.1445, extra loss: 0.6172\n",
      "Epoch: 3, Step: 83, G Loss: 1.3256, D Loss: 1.5005, mask loss: 1.0095, extra loss: 0.6321\n",
      "Epoch: 3, Step: 84, G Loss: 1.6164, D Loss: 1.5005, mask loss: 1.3081, extra loss: 0.6166\n",
      "Epoch: 3, Step: 85, G Loss: 1.4340, D Loss: 1.5005, mask loss: 1.1096, extra loss: 0.6488\n",
      "Epoch: 3, Step: 86, G Loss: 1.3402, D Loss: 1.5005, mask loss: 1.0206, extra loss: 0.6393\n",
      "Epoch: 3, Step: 87, G Loss: 1.2418, D Loss: 1.5005, mask loss: 0.9515, extra loss: 0.5807\n",
      "Epoch: 3, Step: 88, G Loss: 1.4459, D Loss: 1.5005, mask loss: 1.1471, extra loss: 0.5976\n",
      "Epoch: 3, Step: 89, G Loss: 1.2715, D Loss: 1.5005, mask loss: 0.9588, extra loss: 0.6253\n",
      "Epoch: 3, Step: 90, G Loss: 1.6475, D Loss: 1.5005, mask loss: 1.3046, extra loss: 0.6859\n",
      "Epoch: 3, Step: 91, G Loss: 1.4071, D Loss: 1.5555, mask loss: 1.0587, extra loss: 0.6969\n",
      "Epoch: 3, Step: 92, G Loss: 1.4389, D Loss: 1.5555, mask loss: 1.1120, extra loss: 0.6538\n",
      "Epoch: 3, Step: 93, G Loss: 1.5029, D Loss: 1.5555, mask loss: 1.1687, extra loss: 0.6685\n",
      "Epoch: 3, Step: 94, G Loss: 1.5444, D Loss: 1.5555, mask loss: 1.2321, extra loss: 0.6245\n",
      "Epoch: 3, Step: 95, G Loss: 1.4540, D Loss: 1.5555, mask loss: 1.1392, extra loss: 0.6295\n",
      "Epoch: 3, Step: 96, G Loss: 1.3683, D Loss: 1.5555, mask loss: 1.0611, extra loss: 0.6144\n",
      "Epoch: 3, Step: 97, G Loss: 1.6581, D Loss: 1.5555, mask loss: 1.3319, extra loss: 0.6523\n",
      "Epoch: 3, Step: 98, G Loss: 1.5937, D Loss: 1.5555, mask loss: 1.2913, extra loss: 0.6048\n",
      "Epoch: 3, Step: 99, G Loss: 1.3966, D Loss: 1.5555, mask loss: 1.0710, extra loss: 0.6512\n",
      "Epoch: 3, Step: 100, G Loss: 1.3529, D Loss: 1.5555, mask loss: 1.0356, extra loss: 0.6346\n",
      "Epoch: 3, Step: 101, G Loss: 1.3587, D Loss: 1.5175, mask loss: 1.0529, extra loss: 0.6117\n",
      "Epoch: 3, Step: 102, G Loss: 1.6760, D Loss: 1.5175, mask loss: 1.3635, extra loss: 0.6250\n",
      "Epoch: 3, Step: 103, G Loss: 1.4195, D Loss: 1.5175, mask loss: 1.0836, extra loss: 0.6717\n",
      "Epoch: 3, Step: 104, G Loss: 1.4085, D Loss: 1.5175, mask loss: 1.0759, extra loss: 0.6651\n",
      "Epoch: 3, Step: 105, G Loss: 1.4610, D Loss: 1.5175, mask loss: 1.1209, extra loss: 0.6801\n",
      "Epoch: 3, Step: 106, G Loss: 1.4298, D Loss: 1.5175, mask loss: 1.1040, extra loss: 0.6517\n",
      "Epoch: 3, Step: 107, G Loss: 1.5237, D Loss: 1.5175, mask loss: 1.1982, extra loss: 0.6511\n",
      "Epoch: 3, Step: 108, G Loss: 1.2794, D Loss: 1.5175, mask loss: 0.9308, extra loss: 0.6972\n",
      "Epoch: 3, Step: 109, G Loss: 1.3398, D Loss: 1.5175, mask loss: 1.0323, extra loss: 0.6151\n",
      "Epoch: 3, Step: 110, G Loss: 1.4879, D Loss: 1.5175, mask loss: 1.1534, extra loss: 0.6689\n",
      "Epoch: 3, Step: 111, G Loss: 1.5503, D Loss: 1.5482, mask loss: 1.1800, extra loss: 0.7404\n",
      "Epoch: 3, Step: 112, G Loss: 1.3547, D Loss: 1.5482, mask loss: 1.0146, extra loss: 0.6801\n",
      "Epoch: 3, Step: 113, G Loss: 1.3071, D Loss: 1.5482, mask loss: 0.9450, extra loss: 0.7242\n",
      "Epoch: 3, Step: 114, G Loss: 1.5883, D Loss: 1.5482, mask loss: 1.2367, extra loss: 0.7033\n",
      "Epoch: 3, Step: 115, G Loss: 1.3840, D Loss: 1.5482, mask loss: 1.0266, extra loss: 0.7148\n",
      "Epoch: 3, Step: 116, G Loss: 1.6455, D Loss: 1.5482, mask loss: 1.3024, extra loss: 0.6862\n",
      "Epoch: 3, Step: 117, G Loss: 1.3589, D Loss: 1.5482, mask loss: 0.9885, extra loss: 0.7408\n",
      "Epoch: 3, Step: 118, G Loss: 1.4873, D Loss: 1.5482, mask loss: 1.1267, extra loss: 0.7212\n",
      "Epoch: 3, Step: 119, G Loss: 1.4632, D Loss: 1.5482, mask loss: 1.1192, extra loss: 0.6881\n",
      "Epoch: 3, Step: 120, G Loss: 1.4060, D Loss: 1.5482, mask loss: 1.0750, extra loss: 0.6619\n",
      "Epoch: 3, Step: 121, G Loss: 1.5236, D Loss: 1.6751, mask loss: 1.1564, extra loss: 0.7342\n",
      "Epoch: 3, Step: 122, G Loss: 1.5099, D Loss: 1.6751, mask loss: 1.1353, extra loss: 0.7491\n",
      "Epoch: 3, Step: 123, G Loss: 1.3211, D Loss: 1.6751, mask loss: 0.9661, extra loss: 0.7100\n",
      "Epoch: 3, Step: 124, G Loss: 1.5966, D Loss: 1.6751, mask loss: 1.2435, extra loss: 0.7061\n",
      "Epoch: 3, Step: 125, G Loss: 1.6363, D Loss: 1.6751, mask loss: 1.2557, extra loss: 0.7614\n",
      "Epoch: 3, Step: 126, G Loss: 1.5059, D Loss: 1.6751, mask loss: 1.1389, extra loss: 0.7340\n",
      "Epoch: 3, Step: 127, G Loss: 1.5080, D Loss: 1.6751, mask loss: 1.1659, extra loss: 0.6841\n",
      "Epoch: 3, Step: 128, G Loss: 1.4099, D Loss: 1.6751, mask loss: 1.0562, extra loss: 0.7073\n",
      "Epoch: 3, Step: 129, G Loss: 1.2952, D Loss: 1.6751, mask loss: 0.9335, extra loss: 0.7234\n",
      "Epoch: 3, Step: 130, G Loss: 1.3197, D Loss: 1.6751, mask loss: 0.9632, extra loss: 0.7131\n",
      "Epoch: 3, Step: 131, G Loss: 1.3918, D Loss: 1.4986, mask loss: 1.0130, extra loss: 0.7576\n",
      "Epoch: 3, Step: 132, G Loss: 1.3655, D Loss: 1.4986, mask loss: 1.0040, extra loss: 0.7230\n",
      "Epoch: 3, Step: 133, G Loss: 1.6727, D Loss: 1.4986, mask loss: 1.3175, extra loss: 0.7104\n",
      "Epoch: 3, Step: 134, G Loss: 1.3900, D Loss: 1.4986, mask loss: 1.0485, extra loss: 0.6831\n",
      "Epoch: 3, Step: 135, G Loss: 1.4200, D Loss: 1.4986, mask loss: 1.0757, extra loss: 0.6886\n",
      "Epoch: 3, Step: 136, G Loss: 1.3853, D Loss: 1.4986, mask loss: 1.0114, extra loss: 0.7477\n",
      "Epoch: 3, Step: 137, G Loss: 1.5115, D Loss: 1.4986, mask loss: 1.1496, extra loss: 0.7236\n",
      "Epoch: 3, Step: 138, G Loss: 1.4978, D Loss: 1.4986, mask loss: 1.1475, extra loss: 0.7005\n",
      "Epoch: 3, Step: 139, G Loss: 1.3983, D Loss: 1.4986, mask loss: 1.0503, extra loss: 0.6961\n",
      "Epoch: 3, Step: 140, G Loss: 1.3872, D Loss: 1.4986, mask loss: 1.0330, extra loss: 0.7084\n",
      "Epoch: 3, Step: 141, G Loss: 1.2893, D Loss: 1.5870, mask loss: 0.9256, extra loss: 0.7274\n",
      "Epoch: 3, Step: 142, G Loss: 1.4674, D Loss: 1.5870, mask loss: 1.1272, extra loss: 0.6805\n",
      "Epoch: 3, Step: 143, G Loss: 1.3423, D Loss: 1.5870, mask loss: 1.0185, extra loss: 0.6475\n",
      "Epoch: 3, Step: 144, G Loss: 1.3789, D Loss: 1.5870, mask loss: 1.0230, extra loss: 0.7117\n",
      "Epoch: 3, Step: 145, G Loss: 1.4193, D Loss: 1.5870, mask loss: 1.0978, extra loss: 0.6430\n",
      "Epoch: 3, Step: 146, G Loss: 1.2823, D Loss: 1.5870, mask loss: 0.9518, extra loss: 0.6610\n",
      "Epoch: 3, Step: 147, G Loss: 1.5170, D Loss: 1.5870, mask loss: 1.1805, extra loss: 0.6731\n",
      "Epoch: 3, Step: 148, G Loss: 1.3997, D Loss: 1.5870, mask loss: 1.0785, extra loss: 0.6425\n",
      "Epoch: 3, Step: 149, G Loss: 1.3926, D Loss: 1.5870, mask loss: 1.0786, extra loss: 0.6280\n",
      "Epoch: 3, Step: 150, G Loss: 1.4323, D Loss: 1.5870, mask loss: 1.1139, extra loss: 0.6369\n",
      "Epoch: 3, Step: 151, G Loss: 1.3444, D Loss: 1.5604, mask loss: 1.0343, extra loss: 0.6202\n",
      "Epoch: 3, Step: 152, G Loss: 1.4696, D Loss: 1.5604, mask loss: 1.1239, extra loss: 0.6915\n",
      "Epoch: 3, Step: 153, G Loss: 1.3488, D Loss: 1.5604, mask loss: 1.0038, extra loss: 0.6899\n",
      "Epoch: 3, Step: 154, G Loss: 1.3746, D Loss: 1.5604, mask loss: 1.0629, extra loss: 0.6235\n",
      "Epoch: 3, Step: 155, G Loss: 1.3599, D Loss: 1.5604, mask loss: 1.0237, extra loss: 0.6723\n",
      "Epoch: 3, Step: 156, G Loss: 1.3169, D Loss: 1.5604, mask loss: 0.9985, extra loss: 0.6367\n",
      "Epoch: 3, Step: 157, G Loss: 1.3955, D Loss: 1.5604, mask loss: 1.0780, extra loss: 0.6351\n",
      "Epoch: 3, Step: 158, G Loss: 1.4096, D Loss: 1.5604, mask loss: 1.1084, extra loss: 0.6024\n",
      "Epoch: 3, Step: 159, G Loss: 1.3686, D Loss: 1.5604, mask loss: 1.0371, extra loss: 0.6630\n",
      "Epoch: 3, Step: 160, G Loss: 1.4194, D Loss: 1.5604, mask loss: 1.1092, extra loss: 0.6203\n",
      "Epoch: 3, Step: 161, G Loss: 1.2696, D Loss: 1.5835, mask loss: 0.9427, extra loss: 0.6538\n",
      "Epoch: 3, Step: 162, G Loss: 1.3925, D Loss: 1.5835, mask loss: 1.0810, extra loss: 0.6231\n",
      "Epoch: 3, Step: 163, G Loss: 1.4340, D Loss: 1.5835, mask loss: 1.1102, extra loss: 0.6477\n",
      "Epoch: 3, Step: 164, G Loss: 1.3173, D Loss: 1.5835, mask loss: 1.0055, extra loss: 0.6236\n",
      "Epoch: 3, Step: 165, G Loss: 1.3428, D Loss: 1.5835, mask loss: 1.0102, extra loss: 0.6652\n",
      "Epoch: 3, Step: 166, G Loss: 1.4791, D Loss: 1.5835, mask loss: 1.1511, extra loss: 0.6559\n",
      "Epoch: 3, Step: 167, G Loss: 1.2676, D Loss: 1.5835, mask loss: 0.9334, extra loss: 0.6684\n",
      "Epoch: 3, Step: 168, G Loss: 1.2477, D Loss: 1.5835, mask loss: 0.9461, extra loss: 0.6032\n",
      "Epoch: 3, Step: 169, G Loss: 1.4538, D Loss: 1.5835, mask loss: 1.1134, extra loss: 0.6808\n",
      "Epoch: 3, Step: 170, G Loss: 1.4207, D Loss: 1.5835, mask loss: 1.0939, extra loss: 0.6536\n",
      "Epoch: 3, Step: 171, G Loss: 1.4382, D Loss: 1.5001, mask loss: 1.0792, extra loss: 0.7180\n",
      "Epoch: 3, Step: 172, G Loss: 1.3754, D Loss: 1.5001, mask loss: 1.0521, extra loss: 0.6466\n",
      "Epoch: 3, Step: 173, G Loss: 1.3906, D Loss: 1.5001, mask loss: 1.0463, extra loss: 0.6887\n",
      "Epoch: 3, Step: 174, G Loss: 1.3674, D Loss: 1.5001, mask loss: 1.0299, extra loss: 0.6751\n",
      "Epoch: 3, Step: 175, G Loss: 1.5557, D Loss: 1.5001, mask loss: 1.2419, extra loss: 0.6276\n",
      "Epoch: 3, Step: 176, G Loss: 1.2570, D Loss: 1.5001, mask loss: 0.9238, extra loss: 0.6664\n",
      "Epoch: 3, Step: 177, G Loss: 1.5033, D Loss: 1.5001, mask loss: 1.1431, extra loss: 0.7204\n",
      "Epoch: 3, Step: 178, G Loss: 1.3557, D Loss: 1.5001, mask loss: 1.0171, extra loss: 0.6773\n",
      "Epoch: 3, Step: 179, G Loss: 1.5719, D Loss: 1.5001, mask loss: 1.2482, extra loss: 0.6474\n",
      "Epoch: 3, Step: 180, G Loss: 1.4190, D Loss: 1.5001, mask loss: 1.0766, extra loss: 0.6849\n",
      "Epoch: 3, Step: 181, G Loss: 1.2939, D Loss: 1.4790, mask loss: 0.9421, extra loss: 0.7037\n",
      "Epoch: 3, Step: 182, G Loss: 1.2690, D Loss: 1.4790, mask loss: 0.9310, extra loss: 0.6760\n",
      "Epoch: 3, Step: 183, G Loss: 1.4509, D Loss: 1.4790, mask loss: 1.0886, extra loss: 0.7245\n",
      "Epoch: 3, Step: 184, G Loss: 1.3784, D Loss: 1.4790, mask loss: 1.0532, extra loss: 0.6503\n",
      "Epoch: 3, Step: 185, G Loss: 1.4180, D Loss: 1.4790, mask loss: 1.0477, extra loss: 0.7406\n",
      "Epoch: 3, Step: 186, G Loss: 1.4656, D Loss: 1.4790, mask loss: 1.1402, extra loss: 0.6507\n",
      "Epoch: 3, Step: 187, G Loss: 1.3593, D Loss: 1.4790, mask loss: 1.0181, extra loss: 0.6825\n",
      "Epoch: 3, Step: 188, G Loss: 1.4101, D Loss: 1.4790, mask loss: 1.0783, extra loss: 0.6636\n",
      "Epoch: 3, Step: 189, G Loss: 1.5278, D Loss: 1.4790, mask loss: 1.2133, extra loss: 0.6291\n",
      "Epoch: 3, Step: 190, G Loss: 1.2873, D Loss: 1.4790, mask loss: 0.9698, extra loss: 0.6350\n",
      "Epoch: 3, Step: 191, G Loss: 1.2010, D Loss: 1.4672, mask loss: 0.8644, extra loss: 0.6730\n",
      "Epoch: 3, Step: 192, G Loss: 1.4871, D Loss: 1.4672, mask loss: 1.1412, extra loss: 0.6919\n",
      "Epoch: 3, Step: 193, G Loss: 1.5989, D Loss: 1.4672, mask loss: 1.2871, extra loss: 0.6237\n",
      "Epoch: 3, Step: 194, G Loss: 1.3272, D Loss: 1.4672, mask loss: 0.9882, extra loss: 0.6778\n",
      "Epoch: 3, Step: 195, G Loss: 1.3658, D Loss: 1.4672, mask loss: 1.0426, extra loss: 0.6463\n",
      "Epoch: 3, Step: 196, G Loss: 1.4293, D Loss: 1.4672, mask loss: 1.1089, extra loss: 0.6408\n",
      "Epoch: 3, Step: 197, G Loss: 1.3158, D Loss: 1.4672, mask loss: 0.9860, extra loss: 0.6597\n",
      "Epoch: 3, Step: 198, G Loss: 1.4723, D Loss: 1.4672, mask loss: 1.1473, extra loss: 0.6501\n",
      "Epoch: 3, Step: 199, G Loss: 1.4395, D Loss: 1.4672, mask loss: 1.0966, extra loss: 0.6859\n",
      "Epoch: 3, Step: 200, G Loss: 1.3801, D Loss: 1.4672, mask loss: 1.0236, extra loss: 0.7130\n",
      "Epoch: 3, Step: 201, G Loss: 1.5438, D Loss: 1.4377, mask loss: 1.2035, extra loss: 0.6807\n",
      "Epoch: 3, Step: 202, G Loss: 1.5461, D Loss: 1.4377, mask loss: 1.2237, extra loss: 0.6449\n",
      "Epoch: 3, Step: 203, G Loss: 1.4644, D Loss: 1.4377, mask loss: 1.1532, extra loss: 0.6224\n",
      "Epoch: 3, Step: 204, G Loss: 1.6305, D Loss: 1.4377, mask loss: 1.3234, extra loss: 0.6142\n",
      "Epoch: 3, Step: 205, G Loss: 1.4921, D Loss: 1.4377, mask loss: 1.1653, extra loss: 0.6535\n",
      "Epoch: 3, Step: 206, G Loss: 1.4702, D Loss: 1.4377, mask loss: 1.1607, extra loss: 0.6192\n",
      "Epoch: 3, Step: 207, G Loss: 1.4696, D Loss: 1.4377, mask loss: 1.1594, extra loss: 0.6204\n",
      "Epoch: 3, Step: 208, G Loss: 1.3761, D Loss: 1.4377, mask loss: 1.0800, extra loss: 0.5923\n",
      "Epoch: 3, Step: 209, G Loss: 1.5767, D Loss: 1.4377, mask loss: 1.2758, extra loss: 0.6017\n",
      "Epoch: 3, Step: 210, G Loss: 1.3126, D Loss: 1.4377, mask loss: 1.0138, extra loss: 0.5977\n",
      "Epoch: 3, Step: 211, G Loss: 1.3580, D Loss: 1.5418, mask loss: 1.0412, extra loss: 0.6337\n",
      "Epoch: 3, Step: 212, G Loss: 1.4147, D Loss: 1.5418, mask loss: 1.0968, extra loss: 0.6357\n",
      "Epoch: 3, Step: 213, G Loss: 1.3359, D Loss: 1.5418, mask loss: 1.0402, extra loss: 0.5915\n",
      "Epoch: 3, Step: 214, G Loss: 1.6149, D Loss: 1.5418, mask loss: 1.3007, extra loss: 0.6286\n",
      "Epoch: 3, Step: 215, G Loss: 1.4626, D Loss: 1.5418, mask loss: 1.1689, extra loss: 0.5875\n",
      "Epoch: 3, Step: 216, G Loss: 1.4220, D Loss: 1.5418, mask loss: 1.1060, extra loss: 0.6320\n",
      "Epoch: 3, Step: 217, G Loss: 1.3941, D Loss: 1.5418, mask loss: 1.0834, extra loss: 0.6213\n",
      "Epoch: 3, Step: 218, G Loss: 1.6771, D Loss: 1.5418, mask loss: 1.3576, extra loss: 0.6390\n",
      "Epoch: 3, Step: 219, G Loss: 1.2774, D Loss: 1.5418, mask loss: 0.9767, extra loss: 0.6014\n",
      "Epoch: 3, Step: 220, G Loss: 1.3781, D Loss: 1.5418, mask loss: 1.0688, extra loss: 0.6187\n",
      "Epoch: 3, Step: 221, G Loss: 1.2746, D Loss: 1.5010, mask loss: 0.9771, extra loss: 0.5950\n",
      "Epoch: 3, Step: 222, G Loss: 1.4626, D Loss: 1.5010, mask loss: 1.1576, extra loss: 0.6100\n",
      "Epoch: 3, Step: 223, G Loss: 1.2709, D Loss: 1.5010, mask loss: 0.9730, extra loss: 0.5960\n",
      "Epoch: 3, Step: 224, G Loss: 1.3056, D Loss: 1.5010, mask loss: 1.0036, extra loss: 0.6040\n",
      "Epoch: 3, Step: 225, G Loss: 1.4582, D Loss: 1.5010, mask loss: 1.1649, extra loss: 0.5868\n",
      "Epoch: 3, Step: 226, G Loss: 1.5045, D Loss: 1.5010, mask loss: 1.2117, extra loss: 0.5856\n",
      "Epoch: 3, Step: 227, G Loss: 1.2878, D Loss: 1.5010, mask loss: 1.0021, extra loss: 0.5715\n",
      "Epoch: 3, Step: 228, G Loss: 1.5210, D Loss: 1.5010, mask loss: 1.2172, extra loss: 0.6077\n",
      "Epoch: 3, Step: 229, G Loss: 1.3197, D Loss: 1.5010, mask loss: 1.0377, extra loss: 0.5640\n",
      "Epoch: 3, Step: 230, G Loss: 1.4535, D Loss: 1.5010, mask loss: 1.1510, extra loss: 0.6050\n",
      "Epoch: 3, Step: 231, G Loss: 1.3052, D Loss: 1.5299, mask loss: 0.9996, extra loss: 0.6112\n",
      "Epoch: 3, Step: 232, G Loss: 1.4104, D Loss: 1.5299, mask loss: 1.1070, extra loss: 0.6068\n",
      "Epoch: 3, Step: 233, G Loss: 1.3915, D Loss: 1.5299, mask loss: 1.0887, extra loss: 0.6056\n",
      "Epoch: 3, Step: 234, G Loss: 1.4264, D Loss: 1.5299, mask loss: 1.1212, extra loss: 0.6102\n",
      "Epoch: 3, Step: 235, G Loss: 1.2901, D Loss: 1.5299, mask loss: 0.9847, extra loss: 0.6108\n",
      "Epoch: 3, Step: 236, G Loss: 1.2142, D Loss: 1.5299, mask loss: 0.9059, extra loss: 0.6165\n",
      "Epoch: 3, Step: 237, G Loss: 1.3992, D Loss: 1.5299, mask loss: 1.0911, extra loss: 0.6160\n",
      "Epoch: 3, Step: 238, G Loss: 1.1976, D Loss: 1.5299, mask loss: 0.8974, extra loss: 0.6003\n",
      "Epoch: 3, Step: 239, G Loss: 1.2875, D Loss: 1.5299, mask loss: 0.9878, extra loss: 0.5994\n",
      "Epoch: 3, Step: 240, G Loss: 1.2923, D Loss: 1.5299, mask loss: 0.9878, extra loss: 0.6090\n",
      "Epoch: 3, Step: 241, G Loss: 1.2821, D Loss: 1.4600, mask loss: 0.9681, extra loss: 0.6280\n",
      "Epoch: 3, Step: 242, G Loss: 1.4795, D Loss: 1.4600, mask loss: 1.1192, extra loss: 0.7206\n",
      "Epoch: 3, Step: 243, G Loss: 1.2938, D Loss: 1.4600, mask loss: 0.9608, extra loss: 0.6661\n",
      "Epoch: 3, Step: 244, G Loss: 1.2737, D Loss: 1.4600, mask loss: 0.9479, extra loss: 0.6517\n",
      "Epoch: 3, Step: 245, G Loss: 1.2540, D Loss: 1.4600, mask loss: 0.9209, extra loss: 0.6663\n",
      "Epoch: 3, Step: 246, G Loss: 1.2502, D Loss: 1.4600, mask loss: 0.9449, extra loss: 0.6107\n",
      "Epoch: 3, Step: 247, G Loss: 1.3024, D Loss: 1.4600, mask loss: 0.9782, extra loss: 0.6484\n",
      "Epoch: 3, Step: 248, G Loss: 1.4544, D Loss: 1.4600, mask loss: 1.1098, extra loss: 0.6893\n",
      "Epoch: 3, Step: 249, G Loss: 1.3684, D Loss: 1.4600, mask loss: 1.0353, extra loss: 0.6662\n",
      "Epoch: 3, Step: 250, G Loss: 1.3385, D Loss: 1.4600, mask loss: 1.0112, extra loss: 0.6546\n",
      "Epoch: 3, Step: 251, G Loss: 1.2697, D Loss: 1.4675, mask loss: 0.9350, extra loss: 0.6694\n",
      "Epoch: 3, Step: 252, G Loss: 1.4370, D Loss: 1.4675, mask loss: 1.0944, extra loss: 0.6851\n",
      "Epoch: 3, Step: 253, G Loss: 1.3816, D Loss: 1.4675, mask loss: 1.0479, extra loss: 0.6673\n",
      "Epoch: 3, Step: 254, G Loss: 1.3436, D Loss: 1.4675, mask loss: 1.0259, extra loss: 0.6353\n",
      "Epoch: 3, Step: 255, G Loss: 1.2259, D Loss: 1.4675, mask loss: 0.9163, extra loss: 0.6193\n",
      "Epoch: 3, Step: 256, G Loss: 1.3917, D Loss: 1.4675, mask loss: 1.0634, extra loss: 0.6565\n",
      "Epoch: 3, Step: 257, G Loss: 1.2835, D Loss: 1.4675, mask loss: 0.9565, extra loss: 0.6541\n",
      "Epoch: 3, Step: 258, G Loss: 1.3363, D Loss: 1.4675, mask loss: 1.0264, extra loss: 0.6199\n",
      "Epoch: 3, Step: 259, G Loss: 1.2152, D Loss: 1.4675, mask loss: 0.9011, extra loss: 0.6282\n",
      "Epoch: 3, Step: 260, G Loss: 1.3240, D Loss: 1.4675, mask loss: 0.9996, extra loss: 0.6489\n",
      "Epoch: 3, Step: 261, G Loss: 1.3276, D Loss: 1.4837, mask loss: 0.9823, extra loss: 0.6906\n",
      "Epoch: 3, Step: 262, G Loss: 1.2894, D Loss: 1.4837, mask loss: 0.9381, extra loss: 0.7027\n",
      "Epoch: 3, Step: 263, G Loss: 1.4490, D Loss: 1.4837, mask loss: 1.1215, extra loss: 0.6549\n",
      "Epoch: 3, Step: 264, G Loss: 1.3605, D Loss: 1.4837, mask loss: 1.0314, extra loss: 0.6583\n",
      "Epoch: 3, Step: 265, G Loss: 1.2894, D Loss: 1.4837, mask loss: 0.9337, extra loss: 0.7115\n",
      "Epoch: 3, Step: 266, G Loss: 1.3677, D Loss: 1.4837, mask loss: 1.0212, extra loss: 0.6929\n",
      "Epoch: 3, Step: 267, G Loss: 1.3233, D Loss: 1.4837, mask loss: 1.0000, extra loss: 0.6465\n",
      "Epoch: 3, Step: 268, G Loss: 1.3240, D Loss: 1.4837, mask loss: 1.0037, extra loss: 0.6406\n",
      "Epoch: 3, Step: 269, G Loss: 1.3298, D Loss: 1.4837, mask loss: 0.9828, extra loss: 0.6940\n",
      "Epoch: 3, Step: 270, G Loss: 1.3399, D Loss: 1.4837, mask loss: 0.9857, extra loss: 0.7085\n",
      "Epoch: 3, Step: 271, G Loss: 1.3502, D Loss: 1.4415, mask loss: 0.9989, extra loss: 0.7026\n",
      "Epoch: 3, Step: 272, G Loss: 1.2753, D Loss: 1.4415, mask loss: 0.9231, extra loss: 0.7044\n",
      "Epoch: 3, Step: 273, G Loss: 1.3465, D Loss: 1.4415, mask loss: 0.9922, extra loss: 0.7086\n",
      "Epoch: 3, Step: 274, G Loss: 1.2896, D Loss: 1.4415, mask loss: 0.9374, extra loss: 0.7045\n",
      "Epoch: 3, Step: 275, G Loss: 1.3875, D Loss: 1.4415, mask loss: 1.0366, extra loss: 0.7018\n",
      "Epoch: 3, Step: 276, G Loss: 1.3170, D Loss: 1.4415, mask loss: 0.9675, extra loss: 0.6989\n",
      "Epoch: 3, Step: 277, G Loss: 1.2451, D Loss: 1.4415, mask loss: 0.8952, extra loss: 0.6998\n",
      "Epoch: 3, Step: 278, G Loss: 1.4328, D Loss: 1.4415, mask loss: 1.0947, extra loss: 0.6761\n",
      "Epoch: 3, Step: 279, G Loss: 1.4614, D Loss: 1.4415, mask loss: 1.1145, extra loss: 0.6938\n",
      "Epoch: 3, Step: 280, G Loss: 1.3818, D Loss: 1.4415, mask loss: 1.0282, extra loss: 0.7072\n",
      "Epoch: 3, Step: 281, G Loss: 1.3725, D Loss: 1.4339, mask loss: 1.0363, extra loss: 0.6723\n",
      "Epoch: 3, Step: 282, G Loss: 1.3789, D Loss: 1.4339, mask loss: 1.0298, extra loss: 0.6983\n",
      "Epoch: 3, Step: 283, G Loss: 1.4979, D Loss: 1.4339, mask loss: 1.1426, extra loss: 0.7107\n",
      "Epoch: 3, Step: 284, G Loss: 1.3786, D Loss: 1.4339, mask loss: 1.0050, extra loss: 0.7472\n",
      "Epoch: 3, Step: 285, G Loss: 1.3676, D Loss: 1.4339, mask loss: 0.9879, extra loss: 0.7596\n",
      "Epoch: 3, Step: 286, G Loss: 1.2176, D Loss: 1.4339, mask loss: 0.8602, extra loss: 0.7147\n",
      "Epoch: 3, Step: 287, G Loss: 1.3751, D Loss: 1.4339, mask loss: 1.0365, extra loss: 0.6773\n",
      "Epoch: 3, Step: 288, G Loss: 1.2312, D Loss: 1.4339, mask loss: 0.8827, extra loss: 0.6970\n",
      "Epoch: 3, Step: 289, G Loss: 1.3826, D Loss: 1.4339, mask loss: 1.0329, extra loss: 0.6995\n",
      "Epoch: 3, Step: 290, G Loss: 1.4175, D Loss: 1.4339, mask loss: 1.0841, extra loss: 0.6668\n",
      "Epoch: 3, Step: 291, G Loss: 1.2820, D Loss: 1.4365, mask loss: 0.9420, extra loss: 0.6800\n",
      "Epoch: 3, Step: 292, G Loss: 1.4915, D Loss: 1.4365, mask loss: 1.1640, extra loss: 0.6550\n",
      "Epoch: 3, Step: 293, G Loss: 1.3273, D Loss: 1.4365, mask loss: 0.9886, extra loss: 0.6776\n",
      "Epoch: 3, Step: 294, G Loss: 1.3387, D Loss: 1.4365, mask loss: 0.9704, extra loss: 0.7366\n",
      "Epoch: 3, Step: 295, G Loss: 1.1129, D Loss: 1.4365, mask loss: 0.7730, extra loss: 0.6797\n",
      "Epoch: 3, Step: 296, G Loss: 1.3671, D Loss: 1.4365, mask loss: 1.0216, extra loss: 0.6909\n",
      "Epoch: 3, Step: 297, G Loss: 1.2828, D Loss: 1.4365, mask loss: 0.9619, extra loss: 0.6418\n",
      "Epoch: 3, Step: 298, G Loss: 1.3130, D Loss: 1.4365, mask loss: 0.9964, extra loss: 0.6333\n",
      "Epoch: 3, Step: 299, G Loss: 1.5542, D Loss: 1.4365, mask loss: 1.1730, extra loss: 0.7624\n",
      "Epoch: 3, Step: 300, G Loss: 1.2683, D Loss: 1.4365, mask loss: 0.9231, extra loss: 0.6904\n",
      "Epoch: 3, Step: 301, G Loss: 1.3655, D Loss: 1.4562, mask loss: 1.0366, extra loss: 0.6577\n",
      "Epoch: 3, Step: 302, G Loss: 1.5086, D Loss: 1.4562, mask loss: 1.1540, extra loss: 0.7094\n",
      "Epoch: 3, Step: 303, G Loss: 1.4950, D Loss: 1.4562, mask loss: 1.1364, extra loss: 0.7172\n",
      "Epoch: 3, Step: 304, G Loss: 1.3005, D Loss: 1.4562, mask loss: 0.9545, extra loss: 0.6921\n",
      "Epoch: 3, G Loss: 1.4099(Mask Loss: 1.0779, Extra Loss: 0.6640), D Loss: 1.5072, Train FID: 219.0544, Val FID: 229.9819\n",
      "Epoch: 4, Step: 1, G Loss: 1.2858, D Loss: 1.4494, mask loss: 0.9248, extra loss: 0.7220\n",
      "Epoch: 4, Step: 2, G Loss: 1.2429, D Loss: 1.4494, mask loss: 0.8743, extra loss: 0.7372\n",
      "Epoch: 4, Step: 3, G Loss: 1.4215, D Loss: 1.4494, mask loss: 1.0439, extra loss: 0.7552\n",
      "Epoch: 4, Step: 4, G Loss: 1.4932, D Loss: 1.4494, mask loss: 1.1394, extra loss: 0.7076\n",
      "Epoch: 4, Step: 5, G Loss: 1.6005, D Loss: 1.4494, mask loss: 1.2277, extra loss: 0.7455\n",
      "Epoch: 4, Step: 6, G Loss: 1.5098, D Loss: 1.4494, mask loss: 1.1547, extra loss: 0.7101\n",
      "Epoch: 4, Step: 7, G Loss: 1.4436, D Loss: 1.4494, mask loss: 1.0616, extra loss: 0.7641\n",
      "Epoch: 4, Step: 8, G Loss: 1.5689, D Loss: 1.4494, mask loss: 1.2176, extra loss: 0.7027\n",
      "Epoch: 4, Step: 9, G Loss: 1.5376, D Loss: 1.4494, mask loss: 1.1732, extra loss: 0.7289\n",
      "Epoch: 4, Step: 10, G Loss: 1.2742, D Loss: 1.4494, mask loss: 0.9072, extra loss: 0.7339\n",
      "Epoch: 4, Step: 11, G Loss: 1.3277, D Loss: 1.4639, mask loss: 0.9503, extra loss: 0.7547\n",
      "Epoch: 4, Step: 12, G Loss: 1.4981, D Loss: 1.4639, mask loss: 1.1416, extra loss: 0.7130\n",
      "Epoch: 4, Step: 13, G Loss: 1.3058, D Loss: 1.4639, mask loss: 0.9219, extra loss: 0.7679\n",
      "Epoch: 4, Step: 14, G Loss: 1.4671, D Loss: 1.4639, mask loss: 1.0915, extra loss: 0.7512\n",
      "Epoch: 4, Step: 15, G Loss: 1.4191, D Loss: 1.4639, mask loss: 1.0386, extra loss: 0.7609\n",
      "Epoch: 4, Step: 16, G Loss: 1.4236, D Loss: 1.4639, mask loss: 1.0733, extra loss: 0.7007\n",
      "Epoch: 4, Step: 17, G Loss: 1.4248, D Loss: 1.4639, mask loss: 1.0690, extra loss: 0.7115\n",
      "Epoch: 4, Step: 18, G Loss: 1.3664, D Loss: 1.4639, mask loss: 0.9968, extra loss: 0.7392\n",
      "Epoch: 4, Step: 19, G Loss: 1.3574, D Loss: 1.4639, mask loss: 0.9709, extra loss: 0.7729\n",
      "Epoch: 4, Step: 20, G Loss: 1.2004, D Loss: 1.4639, mask loss: 0.8389, extra loss: 0.7230\n",
      "Epoch: 4, Step: 21, G Loss: 1.4582, D Loss: 1.5163, mask loss: 1.0873, extra loss: 0.7419\n",
      "Epoch: 4, Step: 22, G Loss: 1.4439, D Loss: 1.5163, mask loss: 1.0875, extra loss: 0.7130\n",
      "Epoch: 4, Step: 23, G Loss: 1.4711, D Loss: 1.5163, mask loss: 1.0975, extra loss: 0.7472\n",
      "Epoch: 4, Step: 24, G Loss: 1.4754, D Loss: 1.5163, mask loss: 1.0807, extra loss: 0.7895\n",
      "Epoch: 4, Step: 25, G Loss: 1.4082, D Loss: 1.5163, mask loss: 1.0429, extra loss: 0.7306\n",
      "Epoch: 4, Step: 26, G Loss: 1.3764, D Loss: 1.5163, mask loss: 0.9845, extra loss: 0.7839\n",
      "Epoch: 4, Step: 27, G Loss: 1.3495, D Loss: 1.5163, mask loss: 0.9677, extra loss: 0.7634\n",
      "Epoch: 4, Step: 28, G Loss: 1.4531, D Loss: 1.5163, mask loss: 1.0859, extra loss: 0.7344\n",
      "Epoch: 4, Step: 29, G Loss: 1.2834, D Loss: 1.5163, mask loss: 0.9215, extra loss: 0.7239\n",
      "Epoch: 4, Step: 30, G Loss: 1.2386, D Loss: 1.5163, mask loss: 0.8734, extra loss: 0.7304\n",
      "Epoch: 4, Step: 31, G Loss: 1.4310, D Loss: 1.4695, mask loss: 1.0940, extra loss: 0.6739\n",
      "Epoch: 4, Step: 32, G Loss: 1.5422, D Loss: 1.4695, mask loss: 1.1786, extra loss: 0.7272\n",
      "Epoch: 4, Step: 33, G Loss: 1.4113, D Loss: 1.4695, mask loss: 1.0646, extra loss: 0.6934\n",
      "Epoch: 4, Step: 34, G Loss: 1.3631, D Loss: 1.4695, mask loss: 1.0266, extra loss: 0.6730\n",
      "Epoch: 4, Step: 35, G Loss: 1.5118, D Loss: 1.4695, mask loss: 1.1691, extra loss: 0.6855\n",
      "Epoch: 4, Step: 36, G Loss: 1.3160, D Loss: 1.4695, mask loss: 0.9728, extra loss: 0.6864\n",
      "Epoch: 4, Step: 37, G Loss: 1.4504, D Loss: 1.4695, mask loss: 1.0812, extra loss: 0.7384\n",
      "Epoch: 4, Step: 38, G Loss: 1.2982, D Loss: 1.4695, mask loss: 0.9611, extra loss: 0.6743\n",
      "Epoch: 4, Step: 39, G Loss: 1.5070, D Loss: 1.4695, mask loss: 1.1644, extra loss: 0.6852\n",
      "Epoch: 4, Step: 40, G Loss: 1.2945, D Loss: 1.4695, mask loss: 0.9459, extra loss: 0.6970\n",
      "Epoch: 4, Step: 41, G Loss: 1.5385, D Loss: 1.5512, mask loss: 1.2217, extra loss: 0.6336\n",
      "Epoch: 4, Step: 42, G Loss: 1.6162, D Loss: 1.5512, mask loss: 1.3021, extra loss: 0.6283\n",
      "Epoch: 4, Step: 43, G Loss: 1.3501, D Loss: 1.5512, mask loss: 1.0139, extra loss: 0.6723\n",
      "Epoch: 4, Step: 44, G Loss: 1.3313, D Loss: 1.5512, mask loss: 0.9904, extra loss: 0.6818\n",
      "Epoch: 4, Step: 45, G Loss: 1.1570, D Loss: 1.5512, mask loss: 0.8206, extra loss: 0.6729\n",
      "Epoch: 4, Step: 46, G Loss: 1.3218, D Loss: 1.5512, mask loss: 0.9930, extra loss: 0.6577\n",
      "Epoch: 4, Step: 47, G Loss: 1.1916, D Loss: 1.5512, mask loss: 0.8566, extra loss: 0.6699\n",
      "Epoch: 4, Step: 48, G Loss: 1.3714, D Loss: 1.5512, mask loss: 1.0307, extra loss: 0.6814\n",
      "Epoch: 4, Step: 49, G Loss: 1.2683, D Loss: 1.5512, mask loss: 0.9436, extra loss: 0.6495\n",
      "Epoch: 4, Step: 50, G Loss: 1.3272, D Loss: 1.5512, mask loss: 0.9963, extra loss: 0.6619\n",
      "Epoch: 4, Step: 51, G Loss: 1.3959, D Loss: 1.5440, mask loss: 1.0723, extra loss: 0.6474\n",
      "Epoch: 4, Step: 52, G Loss: 1.3248, D Loss: 1.5440, mask loss: 0.9966, extra loss: 0.6564\n",
      "Epoch: 4, Step: 53, G Loss: 1.2222, D Loss: 1.5440, mask loss: 0.8823, extra loss: 0.6797\n",
      "Epoch: 4, Step: 54, G Loss: 1.3891, D Loss: 1.5440, mask loss: 1.0756, extra loss: 0.6271\n",
      "Epoch: 4, Step: 55, G Loss: 1.4603, D Loss: 1.5440, mask loss: 1.1587, extra loss: 0.6033\n",
      "Epoch: 4, Step: 56, G Loss: 1.3802, D Loss: 1.5440, mask loss: 1.0530, extra loss: 0.6544\n",
      "Epoch: 4, Step: 57, G Loss: 1.3048, D Loss: 1.5440, mask loss: 0.9837, extra loss: 0.6423\n",
      "Epoch: 4, Step: 58, G Loss: 1.2134, D Loss: 1.5440, mask loss: 0.9148, extra loss: 0.5972\n",
      "Epoch: 4, Step: 59, G Loss: 1.3312, D Loss: 1.5440, mask loss: 1.0027, extra loss: 0.6568\n",
      "Epoch: 4, Step: 60, G Loss: 1.3864, D Loss: 1.5440, mask loss: 1.0692, extra loss: 0.6343\n",
      "Epoch: 4, Step: 61, G Loss: 1.3276, D Loss: 1.4724, mask loss: 1.0144, extra loss: 0.6264\n",
      "Epoch: 4, Step: 62, G Loss: 1.3086, D Loss: 1.4724, mask loss: 0.9931, extra loss: 0.6310\n",
      "Epoch: 4, Step: 63, G Loss: 1.1544, D Loss: 1.4724, mask loss: 0.8557, extra loss: 0.5974\n",
      "Epoch: 4, Step: 64, G Loss: 1.3643, D Loss: 1.4724, mask loss: 1.0528, extra loss: 0.6231\n",
      "Epoch: 4, Step: 65, G Loss: 1.4253, D Loss: 1.4724, mask loss: 1.1021, extra loss: 0.6464\n",
      "Epoch: 4, Step: 66, G Loss: 1.2811, D Loss: 1.4724, mask loss: 0.9637, extra loss: 0.6349\n",
      "Epoch: 4, Step: 67, G Loss: 1.2650, D Loss: 1.4724, mask loss: 0.9626, extra loss: 0.6048\n",
      "Epoch: 4, Step: 68, G Loss: 1.3904, D Loss: 1.4724, mask loss: 1.0831, extra loss: 0.6146\n",
      "Epoch: 4, Step: 69, G Loss: 1.3440, D Loss: 1.4724, mask loss: 1.0315, extra loss: 0.6250\n",
      "Epoch: 4, Step: 70, G Loss: 1.2775, D Loss: 1.4724, mask loss: 0.9694, extra loss: 0.6161\n",
      "Epoch: 4, Step: 71, G Loss: 1.4257, D Loss: 1.4983, mask loss: 1.1147, extra loss: 0.6219\n",
      "Epoch: 4, Step: 72, G Loss: 1.4366, D Loss: 1.4983, mask loss: 1.1329, extra loss: 0.6074\n",
      "Epoch: 4, Step: 73, G Loss: 1.1949, D Loss: 1.4983, mask loss: 0.8910, extra loss: 0.6078\n",
      "Epoch: 4, Step: 74, G Loss: 1.4176, D Loss: 1.4983, mask loss: 1.1195, extra loss: 0.5962\n",
      "Epoch: 4, Step: 75, G Loss: 1.3692, D Loss: 1.4983, mask loss: 1.0553, extra loss: 0.6278\n",
      "Epoch: 4, Step: 76, G Loss: 1.2869, D Loss: 1.4983, mask loss: 0.9950, extra loss: 0.5838\n",
      "Epoch: 4, Step: 77, G Loss: 1.3082, D Loss: 1.4983, mask loss: 0.9895, extra loss: 0.6374\n",
      "Epoch: 4, Step: 78, G Loss: 1.1969, D Loss: 1.4983, mask loss: 0.8958, extra loss: 0.6022\n",
      "Epoch: 4, Step: 79, G Loss: 1.3402, D Loss: 1.4983, mask loss: 1.0332, extra loss: 0.6140\n",
      "Epoch: 4, Step: 80, G Loss: 1.2671, D Loss: 1.4983, mask loss: 0.9698, extra loss: 0.5947\n",
      "Epoch: 4, Step: 81, G Loss: 1.2487, D Loss: 1.4892, mask loss: 0.9465, extra loss: 0.6044\n",
      "Epoch: 4, Step: 82, G Loss: 1.1718, D Loss: 1.4892, mask loss: 0.8768, extra loss: 0.5898\n",
      "Epoch: 4, Step: 83, G Loss: 1.2851, D Loss: 1.4892, mask loss: 0.9809, extra loss: 0.6084\n",
      "Epoch: 4, Step: 84, G Loss: 1.3598, D Loss: 1.4892, mask loss: 1.0499, extra loss: 0.6197\n",
      "Epoch: 4, Step: 85, G Loss: 1.2710, D Loss: 1.4892, mask loss: 0.9761, extra loss: 0.5899\n",
      "Epoch: 4, Step: 86, G Loss: 1.2124, D Loss: 1.4892, mask loss: 0.9262, extra loss: 0.5724\n",
      "Epoch: 4, Step: 87, G Loss: 1.3505, D Loss: 1.4892, mask loss: 1.0428, extra loss: 0.6156\n",
      "Epoch: 4, Step: 88, G Loss: 1.2410, D Loss: 1.4892, mask loss: 0.9358, extra loss: 0.6104\n",
      "Epoch: 4, Step: 89, G Loss: 1.3289, D Loss: 1.4892, mask loss: 1.0354, extra loss: 0.5870\n",
      "Epoch: 4, Step: 90, G Loss: 1.3389, D Loss: 1.4892, mask loss: 1.0430, extra loss: 0.5920\n",
      "Epoch: 4, Step: 91, G Loss: 1.2365, D Loss: 1.4879, mask loss: 0.9246, extra loss: 0.6238\n",
      "Epoch: 4, Step: 92, G Loss: 1.2927, D Loss: 1.4879, mask loss: 0.9862, extra loss: 0.6131\n",
      "Epoch: 4, Step: 93, G Loss: 1.2911, D Loss: 1.4879, mask loss: 0.9798, extra loss: 0.6226\n",
      "Epoch: 4, Step: 94, G Loss: 1.2669, D Loss: 1.4879, mask loss: 0.9591, extra loss: 0.6155\n",
      "Epoch: 4, Step: 95, G Loss: 1.4752, D Loss: 1.4879, mask loss: 1.1528, extra loss: 0.6448\n",
      "Epoch: 4, Step: 96, G Loss: 1.3235, D Loss: 1.4879, mask loss: 0.9913, extra loss: 0.6645\n",
      "Epoch: 4, Step: 97, G Loss: 1.3917, D Loss: 1.4879, mask loss: 1.0662, extra loss: 0.6511\n",
      "Epoch: 4, Step: 98, G Loss: 1.3900, D Loss: 1.4879, mask loss: 1.0545, extra loss: 0.6709\n",
      "Epoch: 4, Step: 99, G Loss: 1.3404, D Loss: 1.4879, mask loss: 1.0246, extra loss: 0.6316\n",
      "Epoch: 4, Step: 100, G Loss: 1.4301, D Loss: 1.4879, mask loss: 1.1170, extra loss: 0.6261\n",
      "Epoch: 4, Step: 101, G Loss: 1.4495, D Loss: 1.4325, mask loss: 1.1206, extra loss: 0.6578\n",
      "Epoch: 4, Step: 102, G Loss: 1.3404, D Loss: 1.4325, mask loss: 1.0012, extra loss: 0.6786\n",
      "Epoch: 4, Step: 103, G Loss: 1.5050, D Loss: 1.4325, mask loss: 1.1689, extra loss: 0.6722\n",
      "Epoch: 4, Step: 104, G Loss: 1.3040, D Loss: 1.4325, mask loss: 0.9567, extra loss: 0.6947\n",
      "Epoch: 4, Step: 105, G Loss: 1.3214, D Loss: 1.4325, mask loss: 0.9943, extra loss: 0.6542\n",
      "Epoch: 4, Step: 106, G Loss: 1.2836, D Loss: 1.4325, mask loss: 0.9527, extra loss: 0.6617\n",
      "Epoch: 4, Step: 107, G Loss: 1.5384, D Loss: 1.4325, mask loss: 1.2202, extra loss: 0.6363\n",
      "Epoch: 4, Step: 108, G Loss: 1.3260, D Loss: 1.4325, mask loss: 1.0025, extra loss: 0.6470\n",
      "Epoch: 4, Step: 109, G Loss: 1.3453, D Loss: 1.4325, mask loss: 1.0258, extra loss: 0.6390\n",
      "Epoch: 4, Step: 110, G Loss: 1.2496, D Loss: 1.4325, mask loss: 0.9190, extra loss: 0.6612\n",
      "Epoch: 4, Step: 111, G Loss: 1.2738, D Loss: 1.4540, mask loss: 0.9337, extra loss: 0.6801\n",
      "Epoch: 4, Step: 112, G Loss: 1.2750, D Loss: 1.4540, mask loss: 0.9120, extra loss: 0.7259\n",
      "Epoch: 4, Step: 113, G Loss: 1.4047, D Loss: 1.4540, mask loss: 1.0676, extra loss: 0.6741\n",
      "Epoch: 4, Step: 114, G Loss: 1.4188, D Loss: 1.4540, mask loss: 1.0752, extra loss: 0.6872\n",
      "Epoch: 4, Step: 115, G Loss: 1.2989, D Loss: 1.4540, mask loss: 0.9504, extra loss: 0.6970\n",
      "Epoch: 4, Step: 116, G Loss: 1.2992, D Loss: 1.4540, mask loss: 0.9717, extra loss: 0.6550\n",
      "Epoch: 4, Step: 117, G Loss: 1.5462, D Loss: 1.4540, mask loss: 1.2117, extra loss: 0.6692\n",
      "Epoch: 4, Step: 118, G Loss: 1.2990, D Loss: 1.4540, mask loss: 0.9541, extra loss: 0.6898\n",
      "Epoch: 4, Step: 119, G Loss: 1.2988, D Loss: 1.4540, mask loss: 0.9514, extra loss: 0.6948\n",
      "Epoch: 4, Step: 120, G Loss: 1.4797, D Loss: 1.4540, mask loss: 1.1341, extra loss: 0.6912\n",
      "Epoch: 4, Step: 121, G Loss: 1.5178, D Loss: 1.4300, mask loss: 1.1577, extra loss: 0.7201\n",
      "Epoch: 4, Step: 122, G Loss: 1.2688, D Loss: 1.4300, mask loss: 0.9120, extra loss: 0.7137\n",
      "Epoch: 4, Step: 123, G Loss: 1.2996, D Loss: 1.4300, mask loss: 0.9261, extra loss: 0.7471\n",
      "Epoch: 4, Step: 124, G Loss: 1.3199, D Loss: 1.4300, mask loss: 0.9669, extra loss: 0.7061\n",
      "Epoch: 4, Step: 125, G Loss: 1.2873, D Loss: 1.4300, mask loss: 0.9077, extra loss: 0.7592\n",
      "Epoch: 4, Step: 126, G Loss: 1.2430, D Loss: 1.4300, mask loss: 0.8828, extra loss: 0.7205\n",
      "Epoch: 4, Step: 127, G Loss: 1.2689, D Loss: 1.4300, mask loss: 0.9025, extra loss: 0.7327\n",
      "Epoch: 4, Step: 128, G Loss: 1.4245, D Loss: 1.4300, mask loss: 1.0632, extra loss: 0.7227\n",
      "Epoch: 4, Step: 129, G Loss: 1.3257, D Loss: 1.4300, mask loss: 0.9693, extra loss: 0.7128\n",
      "Epoch: 4, Step: 130, G Loss: 1.5156, D Loss: 1.4300, mask loss: 1.1326, extra loss: 0.7661\n",
      "Epoch: 4, Step: 131, G Loss: 1.3338, D Loss: 1.4489, mask loss: 0.9462, extra loss: 0.7753\n",
      "Epoch: 4, Step: 132, G Loss: 1.3397, D Loss: 1.4489, mask loss: 0.9497, extra loss: 0.7799\n",
      "Epoch: 4, Step: 133, G Loss: 1.3106, D Loss: 1.4489, mask loss: 0.9220, extra loss: 0.7771\n",
      "Epoch: 4, Step: 134, G Loss: 1.3221, D Loss: 1.4489, mask loss: 0.9790, extra loss: 0.6863\n",
      "Epoch: 4, Step: 135, G Loss: 1.4511, D Loss: 1.4489, mask loss: 1.0737, extra loss: 0.7547\n",
      "Epoch: 4, Step: 136, G Loss: 1.3067, D Loss: 1.4489, mask loss: 0.9427, extra loss: 0.7280\n",
      "Epoch: 4, Step: 137, G Loss: 1.5458, D Loss: 1.4489, mask loss: 1.1866, extra loss: 0.7183\n",
      "Epoch: 4, Step: 138, G Loss: 1.3269, D Loss: 1.4489, mask loss: 0.9818, extra loss: 0.6902\n",
      "Epoch: 4, Step: 139, G Loss: 1.3600, D Loss: 1.4489, mask loss: 1.0099, extra loss: 0.7003\n",
      "Epoch: 4, Step: 140, G Loss: 1.3907, D Loss: 1.4489, mask loss: 1.0258, extra loss: 0.7298\n",
      "Epoch: 4, Step: 141, G Loss: 1.3600, D Loss: 1.4408, mask loss: 0.9850, extra loss: 0.7501\n",
      "Epoch: 4, Step: 142, G Loss: 1.5527, D Loss: 1.4408, mask loss: 1.1814, extra loss: 0.7427\n",
      "Epoch: 4, Step: 143, G Loss: 1.2493, D Loss: 1.4408, mask loss: 0.8931, extra loss: 0.7125\n",
      "Epoch: 4, Step: 144, G Loss: 1.2188, D Loss: 1.4408, mask loss: 0.8714, extra loss: 0.6947\n",
      "Epoch: 4, Step: 145, G Loss: 1.3319, D Loss: 1.4408, mask loss: 0.9672, extra loss: 0.7292\n",
      "Epoch: 4, Step: 146, G Loss: 1.5115, D Loss: 1.4408, mask loss: 1.1573, extra loss: 0.7083\n",
      "Epoch: 4, Step: 147, G Loss: 1.1889, D Loss: 1.4408, mask loss: 0.8453, extra loss: 0.6871\n",
      "Epoch: 4, Step: 148, G Loss: 1.3608, D Loss: 1.4408, mask loss: 0.9825, extra loss: 0.7566\n",
      "Epoch: 4, Step: 149, G Loss: 1.3061, D Loss: 1.4408, mask loss: 0.9189, extra loss: 0.7744\n",
      "Epoch: 4, Step: 150, G Loss: 1.2455, D Loss: 1.4408, mask loss: 0.8827, extra loss: 0.7257\n",
      "Epoch: 4, Step: 151, G Loss: 1.2350, D Loss: 1.4558, mask loss: 0.8630, extra loss: 0.7441\n",
      "Epoch: 4, Step: 152, G Loss: 1.3780, D Loss: 1.4558, mask loss: 0.9728, extra loss: 0.8104\n",
      "Epoch: 4, Step: 153, G Loss: 1.4381, D Loss: 1.4558, mask loss: 1.0532, extra loss: 0.7699\n",
      "Epoch: 4, Step: 154, G Loss: 1.3452, D Loss: 1.4558, mask loss: 0.9741, extra loss: 0.7420\n",
      "Epoch: 4, Step: 155, G Loss: 1.3989, D Loss: 1.4558, mask loss: 1.0143, extra loss: 0.7693\n",
      "Epoch: 4, Step: 156, G Loss: 1.2517, D Loss: 1.4558, mask loss: 0.8926, extra loss: 0.7181\n",
      "Epoch: 4, Step: 157, G Loss: 1.3528, D Loss: 1.4558, mask loss: 1.0016, extra loss: 0.7023\n",
      "Epoch: 4, Step: 158, G Loss: 1.4371, D Loss: 1.4558, mask loss: 1.0445, extra loss: 0.7852\n",
      "Epoch: 4, Step: 159, G Loss: 1.3290, D Loss: 1.4558, mask loss: 0.9512, extra loss: 0.7555\n",
      "Epoch: 4, Step: 160, G Loss: 1.4291, D Loss: 1.4558, mask loss: 1.0556, extra loss: 0.7469\n",
      "Epoch: 4, Step: 161, G Loss: 1.4074, D Loss: 1.4110, mask loss: 1.0523, extra loss: 0.7101\n",
      "Epoch: 4, Step: 162, G Loss: 1.2061, D Loss: 1.4110, mask loss: 0.8517, extra loss: 0.7088\n",
      "Epoch: 4, Step: 163, G Loss: 1.3562, D Loss: 1.4110, mask loss: 0.9900, extra loss: 0.7325\n",
      "Epoch: 4, Step: 164, G Loss: 1.4577, D Loss: 1.4110, mask loss: 1.0932, extra loss: 0.7289\n",
      "Epoch: 4, Step: 165, G Loss: 1.2195, D Loss: 1.4110, mask loss: 0.8720, extra loss: 0.6950\n",
      "Epoch: 4, Step: 166, G Loss: 1.5525, D Loss: 1.4110, mask loss: 1.2003, extra loss: 0.7044\n",
      "Epoch: 4, Step: 167, G Loss: 1.3326, D Loss: 1.4110, mask loss: 0.9784, extra loss: 0.7082\n",
      "Epoch: 4, Step: 168, G Loss: 1.3574, D Loss: 1.4110, mask loss: 1.0084, extra loss: 0.6980\n",
      "Epoch: 4, Step: 169, G Loss: 1.3331, D Loss: 1.4110, mask loss: 0.9642, extra loss: 0.7378\n",
      "Epoch: 4, Step: 170, G Loss: 1.2076, D Loss: 1.4110, mask loss: 0.8559, extra loss: 0.7035\n",
      "Epoch: 4, Step: 171, G Loss: 1.2889, D Loss: 1.4813, mask loss: 0.9455, extra loss: 0.6868\n",
      "Epoch: 4, Step: 172, G Loss: 1.1850, D Loss: 1.4813, mask loss: 0.8493, extra loss: 0.6714\n",
      "Epoch: 4, Step: 173, G Loss: 1.2732, D Loss: 1.4813, mask loss: 0.9421, extra loss: 0.6623\n",
      "Epoch: 4, Step: 174, G Loss: 1.4469, D Loss: 1.4813, mask loss: 1.0981, extra loss: 0.6975\n",
      "Epoch: 4, Step: 175, G Loss: 1.3176, D Loss: 1.4813, mask loss: 0.9576, extra loss: 0.7200\n",
      "Epoch: 4, Step: 176, G Loss: 1.3910, D Loss: 1.4813, mask loss: 1.0390, extra loss: 0.7040\n",
      "Epoch: 4, Step: 177, G Loss: 1.1878, D Loss: 1.4813, mask loss: 0.8446, extra loss: 0.6864\n",
      "Epoch: 4, Step: 178, G Loss: 1.2129, D Loss: 1.4813, mask loss: 0.8620, extra loss: 0.7017\n",
      "Epoch: 4, Step: 179, G Loss: 1.2344, D Loss: 1.4813, mask loss: 0.8829, extra loss: 0.7030\n",
      "Epoch: 4, Step: 180, G Loss: 1.3391, D Loss: 1.4813, mask loss: 1.0226, extra loss: 0.6329\n",
      "Epoch: 4, Step: 181, G Loss: 1.1987, D Loss: 1.4715, mask loss: 0.8683, extra loss: 0.6609\n",
      "Epoch: 4, Step: 182, G Loss: 1.1605, D Loss: 1.4715, mask loss: 0.8359, extra loss: 0.6492\n",
      "Epoch: 4, Step: 183, G Loss: 1.1486, D Loss: 1.4715, mask loss: 0.8147, extra loss: 0.6678\n",
      "Epoch: 4, Step: 184, G Loss: 1.2826, D Loss: 1.4715, mask loss: 0.9607, extra loss: 0.6437\n",
      "Epoch: 4, Step: 185, G Loss: 1.3865, D Loss: 1.4715, mask loss: 1.0643, extra loss: 0.6444\n",
      "Epoch: 4, Step: 186, G Loss: 1.3376, D Loss: 1.4715, mask loss: 1.0184, extra loss: 0.6384\n",
      "Epoch: 4, Step: 187, G Loss: 1.5831, D Loss: 1.4715, mask loss: 1.2600, extra loss: 0.6463\n",
      "Epoch: 4, Step: 188, G Loss: 1.4458, D Loss: 1.4715, mask loss: 1.1261, extra loss: 0.6392\n",
      "Epoch: 4, Step: 189, G Loss: 1.2922, D Loss: 1.4715, mask loss: 0.9731, extra loss: 0.6384\n",
      "Epoch: 4, Step: 190, G Loss: 1.3165, D Loss: 1.4715, mask loss: 0.9809, extra loss: 0.6714\n",
      "Epoch: 4, Step: 191, G Loss: 1.3191, D Loss: 1.4668, mask loss: 0.9937, extra loss: 0.6507\n",
      "Epoch: 4, Step: 192, G Loss: 1.2958, D Loss: 1.4668, mask loss: 0.9830, extra loss: 0.6255\n",
      "Epoch: 4, Step: 193, G Loss: 1.2033, D Loss: 1.4668, mask loss: 0.8929, extra loss: 0.6208\n",
      "Epoch: 4, Step: 194, G Loss: 1.3814, D Loss: 1.4668, mask loss: 1.0621, extra loss: 0.6385\n",
      "Epoch: 4, Step: 195, G Loss: 1.1701, D Loss: 1.4668, mask loss: 0.8608, extra loss: 0.6185\n",
      "Epoch: 4, Step: 196, G Loss: 1.3852, D Loss: 1.4668, mask loss: 1.0549, extra loss: 0.6605\n",
      "Epoch: 4, Step: 197, G Loss: 1.2738, D Loss: 1.4668, mask loss: 0.9793, extra loss: 0.5890\n",
      "Epoch: 4, Step: 198, G Loss: 1.2914, D Loss: 1.4668, mask loss: 0.9966, extra loss: 0.5896\n",
      "Epoch: 4, Step: 199, G Loss: 1.3760, D Loss: 1.4668, mask loss: 1.0737, extra loss: 0.6047\n",
      "Epoch: 4, Step: 200, G Loss: 1.3058, D Loss: 1.4668, mask loss: 1.0058, extra loss: 0.6000\n",
      "Epoch: 4, Step: 201, G Loss: 1.1840, D Loss: 1.4687, mask loss: 0.8737, extra loss: 0.6206\n",
      "Epoch: 4, Step: 202, G Loss: 1.3978, D Loss: 1.4687, mask loss: 1.0907, extra loss: 0.6143\n",
      "Epoch: 4, Step: 203, G Loss: 1.2724, D Loss: 1.4687, mask loss: 0.9919, extra loss: 0.5610\n",
      "Epoch: 4, Step: 204, G Loss: 1.2745, D Loss: 1.4687, mask loss: 0.9951, extra loss: 0.5588\n",
      "Epoch: 4, Step: 205, G Loss: 1.1918, D Loss: 1.4687, mask loss: 0.8989, extra loss: 0.5858\n",
      "Epoch: 4, Step: 206, G Loss: 1.3139, D Loss: 1.4687, mask loss: 0.9975, extra loss: 0.6328\n",
      "Epoch: 4, Step: 207, G Loss: 1.4204, D Loss: 1.4687, mask loss: 1.1030, extra loss: 0.6348\n",
      "Epoch: 4, Step: 208, G Loss: 1.2596, D Loss: 1.4687, mask loss: 0.9576, extra loss: 0.6041\n",
      "Epoch: 4, Step: 209, G Loss: 1.4016, D Loss: 1.4687, mask loss: 1.1013, extra loss: 0.6006\n",
      "Epoch: 4, Step: 210, G Loss: 1.3911, D Loss: 1.4687, mask loss: 1.0839, extra loss: 0.6145\n",
      "Epoch: 4, Step: 211, G Loss: 1.1974, D Loss: 1.4719, mask loss: 0.9024, extra loss: 0.5900\n",
      "Epoch: 4, Step: 212, G Loss: 1.3143, D Loss: 1.4719, mask loss: 1.0287, extra loss: 0.5712\n",
      "Epoch: 4, Step: 213, G Loss: 1.2254, D Loss: 1.4719, mask loss: 0.9357, extra loss: 0.5794\n",
      "Epoch: 4, Step: 214, G Loss: 1.2651, D Loss: 1.4719, mask loss: 0.9624, extra loss: 0.6055\n",
      "Epoch: 4, Step: 215, G Loss: 1.2853, D Loss: 1.4719, mask loss: 0.9707, extra loss: 0.6291\n",
      "Epoch: 4, Step: 216, G Loss: 1.2557, D Loss: 1.4719, mask loss: 0.9591, extra loss: 0.5933\n",
      "Epoch: 4, Step: 217, G Loss: 1.4183, D Loss: 1.4719, mask loss: 1.1305, extra loss: 0.5756\n",
      "Epoch: 4, Step: 218, G Loss: 1.2491, D Loss: 1.4719, mask loss: 0.9532, extra loss: 0.5918\n",
      "Epoch: 4, Step: 219, G Loss: 1.2798, D Loss: 1.4719, mask loss: 0.9660, extra loss: 0.6277\n",
      "Epoch: 4, Step: 220, G Loss: 1.1970, D Loss: 1.4719, mask loss: 0.8970, extra loss: 0.6000\n",
      "Epoch: 4, Step: 221, G Loss: 1.1540, D Loss: 1.4501, mask loss: 0.8407, extra loss: 0.6264\n",
      "Epoch: 4, Step: 222, G Loss: 1.1523, D Loss: 1.4501, mask loss: 0.8343, extra loss: 0.6360\n",
      "Epoch: 4, Step: 223, G Loss: 1.1218, D Loss: 1.4501, mask loss: 0.8225, extra loss: 0.5986\n",
      "Epoch: 4, Step: 224, G Loss: 1.3534, D Loss: 1.4501, mask loss: 1.0498, extra loss: 0.6071\n",
      "Epoch: 4, Step: 225, G Loss: 1.2446, D Loss: 1.4501, mask loss: 0.9584, extra loss: 0.5722\n",
      "Epoch: 4, Step: 226, G Loss: 1.2687, D Loss: 1.4501, mask loss: 0.9749, extra loss: 0.5877\n",
      "Epoch: 4, Step: 227, G Loss: 1.3607, D Loss: 1.4501, mask loss: 1.0502, extra loss: 0.6210\n",
      "Epoch: 4, Step: 228, G Loss: 1.4060, D Loss: 1.4501, mask loss: 1.0886, extra loss: 0.6347\n",
      "Epoch: 4, Step: 229, G Loss: 1.1808, D Loss: 1.4501, mask loss: 0.8523, extra loss: 0.6569\n",
      "Epoch: 4, Step: 230, G Loss: 1.4047, D Loss: 1.4501, mask loss: 1.1041, extra loss: 0.6012\n",
      "Epoch: 4, Step: 231, G Loss: 1.2781, D Loss: 1.4624, mask loss: 0.9411, extra loss: 0.6740\n",
      "Epoch: 4, Step: 232, G Loss: 1.3209, D Loss: 1.4624, mask loss: 0.9800, extra loss: 0.6819\n",
      "Epoch: 4, Step: 233, G Loss: 1.2271, D Loss: 1.4624, mask loss: 0.9079, extra loss: 0.6385\n",
      "Epoch: 4, Step: 234, G Loss: 1.3014, D Loss: 1.4624, mask loss: 0.9844, extra loss: 0.6342\n",
      "Epoch: 4, Step: 235, G Loss: 1.2590, D Loss: 1.4624, mask loss: 0.9383, extra loss: 0.6413\n",
      "Epoch: 4, Step: 236, G Loss: 1.2812, D Loss: 1.4624, mask loss: 0.9564, extra loss: 0.6496\n",
      "Epoch: 4, Step: 237, G Loss: 1.3637, D Loss: 1.4624, mask loss: 1.0319, extra loss: 0.6636\n",
      "Epoch: 4, Step: 238, G Loss: 1.2595, D Loss: 1.4624, mask loss: 0.9389, extra loss: 0.6411\n",
      "Epoch: 4, Step: 239, G Loss: 1.3883, D Loss: 1.4624, mask loss: 1.0787, extra loss: 0.6192\n",
      "Epoch: 4, Step: 240, G Loss: 1.2647, D Loss: 1.4624, mask loss: 0.9711, extra loss: 0.5871\n",
      "Epoch: 4, Step: 241, G Loss: 1.1616, D Loss: 1.5223, mask loss: 0.8400, extra loss: 0.6431\n",
      "Epoch: 4, Step: 242, G Loss: 1.4286, D Loss: 1.5223, mask loss: 1.1009, extra loss: 0.6556\n",
      "Epoch: 4, Step: 243, G Loss: 1.3045, D Loss: 1.5223, mask loss: 0.9636, extra loss: 0.6817\n",
      "Epoch: 4, Step: 244, G Loss: 1.2055, D Loss: 1.5223, mask loss: 0.8853, extra loss: 0.6404\n",
      "Epoch: 4, Step: 245, G Loss: 1.2044, D Loss: 1.5223, mask loss: 0.8711, extra loss: 0.6667\n",
      "Epoch: 4, Step: 246, G Loss: 1.4208, D Loss: 1.5223, mask loss: 1.0895, extra loss: 0.6626\n",
      "Epoch: 4, Step: 247, G Loss: 1.2548, D Loss: 1.5223, mask loss: 0.9192, extra loss: 0.6711\n",
      "Epoch: 4, Step: 248, G Loss: 1.2529, D Loss: 1.5223, mask loss: 0.9123, extra loss: 0.6811\n",
      "Epoch: 4, Step: 249, G Loss: 1.1143, D Loss: 1.5223, mask loss: 0.7633, extra loss: 0.7020\n",
      "Epoch: 4, Step: 250, G Loss: 1.3303, D Loss: 1.5223, mask loss: 0.9923, extra loss: 0.6760\n",
      "Epoch: 4, Step: 251, G Loss: 1.2064, D Loss: 1.4747, mask loss: 0.8644, extra loss: 0.6838\n",
      "Epoch: 4, Step: 252, G Loss: 1.3399, D Loss: 1.4747, mask loss: 0.9952, extra loss: 0.6895\n",
      "Epoch: 4, Step: 253, G Loss: 1.1727, D Loss: 1.4747, mask loss: 0.8318, extra loss: 0.6818\n",
      "Epoch: 4, Step: 254, G Loss: 1.4937, D Loss: 1.4747, mask loss: 1.1476, extra loss: 0.6922\n",
      "Epoch: 4, Step: 255, G Loss: 1.3798, D Loss: 1.4747, mask loss: 1.0306, extra loss: 0.6984\n",
      "Epoch: 4, Step: 256, G Loss: 1.2446, D Loss: 1.4747, mask loss: 0.9103, extra loss: 0.6685\n",
      "Epoch: 4, Step: 257, G Loss: 1.2862, D Loss: 1.4747, mask loss: 0.9507, extra loss: 0.6709\n",
      "Epoch: 4, Step: 258, G Loss: 1.2860, D Loss: 1.4747, mask loss: 0.9428, extra loss: 0.6864\n",
      "Epoch: 4, Step: 259, G Loss: 1.2539, D Loss: 1.4747, mask loss: 0.9188, extra loss: 0.6702\n",
      "Epoch: 4, Step: 260, G Loss: 1.2953, D Loss: 1.4747, mask loss: 0.9453, extra loss: 0.6999\n",
      "Epoch: 4, Step: 261, G Loss: 1.2406, D Loss: 1.4037, mask loss: 0.8947, extra loss: 0.6918\n",
      "Epoch: 4, Step: 262, G Loss: 1.3280, D Loss: 1.4037, mask loss: 0.9743, extra loss: 0.7075\n",
      "Epoch: 4, Step: 263, G Loss: 1.1705, D Loss: 1.4037, mask loss: 0.8319, extra loss: 0.6772\n",
      "Epoch: 4, Step: 264, G Loss: 1.2987, D Loss: 1.4037, mask loss: 0.9379, extra loss: 0.7217\n",
      "Epoch: 4, Step: 265, G Loss: 1.3557, D Loss: 1.4037, mask loss: 1.0253, extra loss: 0.6609\n",
      "Epoch: 4, Step: 266, G Loss: 1.3156, D Loss: 1.4037, mask loss: 0.9632, extra loss: 0.7048\n",
      "Epoch: 4, Step: 267, G Loss: 1.4537, D Loss: 1.4037, mask loss: 1.0907, extra loss: 0.7260\n",
      "Epoch: 4, Step: 268, G Loss: 1.2749, D Loss: 1.4037, mask loss: 0.9311, extra loss: 0.6877\n",
      "Epoch: 4, Step: 269, G Loss: 1.2379, D Loss: 1.4037, mask loss: 0.9014, extra loss: 0.6731\n",
      "Epoch: 4, Step: 270, G Loss: 1.2204, D Loss: 1.4037, mask loss: 0.9152, extra loss: 0.6104\n",
      "Epoch: 4, Step: 271, G Loss: 1.2448, D Loss: 1.4642, mask loss: 0.8966, extra loss: 0.6965\n",
      "Epoch: 4, Step: 272, G Loss: 1.1598, D Loss: 1.4642, mask loss: 0.8102, extra loss: 0.6993\n",
      "Epoch: 4, Step: 273, G Loss: 1.1527, D Loss: 1.4642, mask loss: 0.7921, extra loss: 0.7212\n",
      "Epoch: 4, Step: 274, G Loss: 1.3166, D Loss: 1.4642, mask loss: 0.9818, extra loss: 0.6695\n",
      "Epoch: 4, Step: 275, G Loss: 1.2276, D Loss: 1.4642, mask loss: 0.8941, extra loss: 0.6670\n",
      "Epoch: 4, Step: 276, G Loss: 1.2999, D Loss: 1.4642, mask loss: 0.9822, extra loss: 0.6353\n",
      "Epoch: 4, Step: 277, G Loss: 1.3568, D Loss: 1.4642, mask loss: 1.0178, extra loss: 0.6781\n",
      "Epoch: 4, Step: 278, G Loss: 1.2948, D Loss: 1.4642, mask loss: 0.9701, extra loss: 0.6495\n",
      "Epoch: 4, Step: 279, G Loss: 1.3282, D Loss: 1.4642, mask loss: 1.0305, extra loss: 0.5954\n",
      "Epoch: 4, Step: 280, G Loss: 1.3586, D Loss: 1.4642, mask loss: 1.0410, extra loss: 0.6352\n",
      "Epoch: 4, Step: 281, G Loss: 1.2760, D Loss: 1.4780, mask loss: 0.9533, extra loss: 0.6454\n",
      "Epoch: 4, Step: 282, G Loss: 1.3182, D Loss: 1.4780, mask loss: 0.9881, extra loss: 0.6602\n",
      "Epoch: 4, Step: 283, G Loss: 1.2624, D Loss: 1.4780, mask loss: 0.9192, extra loss: 0.6864\n",
      "Epoch: 4, Step: 284, G Loss: 1.1540, D Loss: 1.4780, mask loss: 0.8120, extra loss: 0.6840\n",
      "Epoch: 4, Step: 285, G Loss: 1.1930, D Loss: 1.4780, mask loss: 0.8429, extra loss: 0.7002\n",
      "Epoch: 4, Step: 286, G Loss: 1.2588, D Loss: 1.4780, mask loss: 0.9127, extra loss: 0.6921\n",
      "Epoch: 4, Step: 287, G Loss: 1.2941, D Loss: 1.4780, mask loss: 0.9388, extra loss: 0.7106\n",
      "Epoch: 4, Step: 288, G Loss: 1.4270, D Loss: 1.4780, mask loss: 1.0923, extra loss: 0.6694\n",
      "Epoch: 4, Step: 289, G Loss: 1.2079, D Loss: 1.4780, mask loss: 0.8534, extra loss: 0.7090\n",
      "Epoch: 4, Step: 290, G Loss: 1.3617, D Loss: 1.4780, mask loss: 0.9941, extra loss: 0.7353\n",
      "Epoch: 4, Step: 291, G Loss: 1.3002, D Loss: 1.4264, mask loss: 0.9690, extra loss: 0.6624\n",
      "Epoch: 4, Step: 292, G Loss: 1.2086, D Loss: 1.4264, mask loss: 0.8559, extra loss: 0.7054\n",
      "Epoch: 4, Step: 293, G Loss: 1.2160, D Loss: 1.4264, mask loss: 0.8928, extra loss: 0.6466\n",
      "Epoch: 4, Step: 294, G Loss: 1.2491, D Loss: 1.4264, mask loss: 0.9086, extra loss: 0.6811\n",
      "Epoch: 4, Step: 295, G Loss: 1.2373, D Loss: 1.4264, mask loss: 0.9008, extra loss: 0.6730\n",
      "Epoch: 4, Step: 296, G Loss: 1.2865, D Loss: 1.4264, mask loss: 0.9503, extra loss: 0.6724\n",
      "Epoch: 4, Step: 297, G Loss: 1.2893, D Loss: 1.4264, mask loss: 0.9705, extra loss: 0.6376\n",
      "Epoch: 4, Step: 298, G Loss: 1.1344, D Loss: 1.4264, mask loss: 0.8119, extra loss: 0.6450\n",
      "Epoch: 4, Step: 299, G Loss: 1.3765, D Loss: 1.4264, mask loss: 1.0654, extra loss: 0.6221\n",
      "Epoch: 4, Step: 300, G Loss: 1.5730, D Loss: 1.4264, mask loss: 1.2433, extra loss: 0.6592\n",
      "Epoch: 4, Step: 301, G Loss: 1.1697, D Loss: 1.4539, mask loss: 0.8360, extra loss: 0.6674\n",
      "Epoch: 4, Step: 302, G Loss: 1.4115, D Loss: 1.4539, mask loss: 1.0985, extra loss: 0.6260\n",
      "Epoch: 4, Step: 303, G Loss: 1.2542, D Loss: 1.4539, mask loss: 0.9044, extra loss: 0.6997\n",
      "Epoch: 4, Step: 304, G Loss: 1.3241, D Loss: 1.4539, mask loss: 0.9994, extra loss: 0.6493\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 6\u001B[0m\n\u001B[0;32m      2\u001B[0m HP_optimizer \u001B[38;5;241m=\u001B[39m HP_optimizer_MCVGAN(img_size\u001B[38;5;241m=\u001B[39mimg_size, NP\u001B[38;5;241m=\u001B[39mNP, select_ratio\u001B[38;5;241m=\u001B[39mselect_ratio, G\u001B[38;5;241m=\u001B[39mG, L\u001B[38;5;241m=\u001B[39mL,\n\u001B[0;32m      3\u001B[0m                                        Pc\u001B[38;5;241m=\u001B[39mPc, Pm\u001B[38;5;241m=\u001B[39mPm, train_mini_epochs\u001B[38;5;241m=\u001B[39mtrain_mini_epochs)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# 获取 best Hyperparameters\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m HP_best \u001B[38;5;241m=\u001B[39m \u001B[43mHP_optimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_best_hyperparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\Pretrain_MCVAE\\HP_optimizer_MCVGAN.py:158\u001B[0m, in \u001B[0;36mHP_optimizer_MCVGAN.get_best_hyperparameters\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    142\u001B[0m     discriminator \u001B[38;5;241m=\u001B[39m Masked_ConViT_GAN_Discriminator(\n\u001B[0;32m    143\u001B[0m         img_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_size,\n\u001B[0;32m    144\u001B[0m         filter_size\u001B[38;5;241m=\u001B[39mfilter_size,\n\u001B[0;32m    145\u001B[0m         num_filters\u001B[38;5;241m=\u001B[39mnum_filters\n\u001B[0;32m    146\u001B[0m     )\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    147\u001B[0m     trainer \u001B[38;5;241m=\u001B[39m Trainer_MCVGAN(\n\u001B[0;32m    148\u001B[0m         generator\u001B[38;5;241m=\u001B[39mgenerator,\n\u001B[0;32m    149\u001B[0m         discriminator\u001B[38;5;241m=\u001B[39mdiscriminator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    155\u001B[0m         epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_mini_epochs\n\u001B[0;32m    156\u001B[0m     )\n\u001B[1;32m--> 158\u001B[0m     fid \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_HP_optim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    159\u001B[0m     fid_score[i] \u001B[38;5;241m=\u001B[39m fid\n\u001B[0;32m    161\u001B[0m fitness \u001B[38;5;241m=\u001B[39m fid_score     \u001B[38;5;66;03m# 以 FID score 作为适应度值\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\Pretrain_MCVAE\\Trainer_MCVGAN.py:239\u001B[0m, in \u001B[0;36mTrainer_MCVGAN.train_HP_optim\u001B[1;34m(self, index, k)\u001B[0m\n\u001B[0;32m    236\u001B[0m average_mask_loss \u001B[38;5;241m=\u001B[39m epoch_mask_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmini_train_loader)\n\u001B[0;32m    237\u001B[0m average_extra_loss \u001B[38;5;241m=\u001B[39m epoch_extra_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmini_train_loader)\n\u001B[1;32m--> 239\u001B[0m train_FID \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_fid_score\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmini_train_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    240\u001B[0m val_FID \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_fid_score(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerator, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmini_validation_loader, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    242\u001B[0m \u001B[38;5;66;03m# 记录日志\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\Pretrain_MCVAE\\Trainer_MCVGAN.py:309\u001B[0m, in \u001B[0;36mTrainer_MCVGAN.get_fid_score\u001B[1;34m(self, model, data_loader, device)\u001B[0m\n\u001B[0;32m    307\u001B[0m         real_images \u001B[38;5;241m=\u001B[39m real_images\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39muint8)\n\u001B[0;32m    308\u001B[0m         fid_metric\u001B[38;5;241m.\u001B[39mupdate(fake_images, real\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m--> 309\u001B[0m         \u001B[43mfid_metric\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreal_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    311\u001B[0m fid_score \u001B[38;5;241m=\u001B[39m fid_metric\u001B[38;5;241m.\u001B[39mcompute()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fid_score\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torchmetrics\\metric.py:550\u001B[0m, in \u001B[0;36mMetric._wrap_update.<locals>.wrapped_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    548\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_grad):\n\u001B[0;32m    549\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 550\u001B[0m         \u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    551\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    552\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected all tensors to be on\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(err):\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torchmetrics\\image\\fid.py:369\u001B[0m, in \u001B[0;36mFrechetInceptionDistance.update\u001B[1;34m(self, imgs, real)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Update the state with extracted features.\u001B[39;00m\n\u001B[0;32m    361\u001B[0m \n\u001B[0;32m    362\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    366\u001B[0m \n\u001B[0;32m    367\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    368\u001B[0m imgs \u001B[38;5;241m=\u001B[39m (imgs \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m255\u001B[39m)\u001B[38;5;241m.\u001B[39mbyte() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnormalize \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mused_custom_model) \u001B[38;5;28;01melse\u001B[39;00m imgs\n\u001B[1;32m--> 369\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minception\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    370\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morig_dtype \u001B[38;5;241m=\u001B[39m features\u001B[38;5;241m.\u001B[39mdtype\n\u001B[0;32m    371\u001B[0m features \u001B[38;5;241m=\u001B[39m features\u001B[38;5;241m.\u001B[39mdouble()\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torchmetrics\\image\\fid.py:156\u001B[0m, in \u001B[0;36mNoTrainInceptionV3.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    155\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Forward pass of neural network with reshaping of output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 156\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_torch_fidelity_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mreshape(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torchmetrics\\image\\fid.py:116\u001B[0m, in \u001B[0;36mNoTrainInceptionV3._torch_fidelity_forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    114\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mMixed_5d(x)\n\u001B[0;32m    115\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mMixed_6a(x)\n\u001B[1;32m--> 116\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMixed_6b\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    117\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mMixed_6c(x)\n\u001B[0;32m    118\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mMixed_6d(x)\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch_fidelity\\feature_extractor_inceptionv3.py:292\u001B[0m, in \u001B[0;36mInceptionC.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    289\u001B[0m branch1x1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbranch1x1(x)\n\u001B[0;32m    291\u001B[0m branch7x7 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbranch7x7_1(x)\n\u001B[1;32m--> 292\u001B[0m branch7x7 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbranch7x7_2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbranch7x7\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    293\u001B[0m branch7x7 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbranch7x7_3(branch7x7)\n\u001B[0;32m    295\u001B[0m branch7x7dbl \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbranch7x7dbl_1(x)\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch_fidelity\\feature_extractor_inceptionv3.py:209\u001B[0m, in \u001B[0;36mBasicConv2d.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m    208\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv(x)\n\u001B[1;32m--> 209\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mrelu(x, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    186\u001B[0m     bn_training \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    188\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[0;32m    192\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m--> 193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[0;32m    196\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_mean\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    203\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    204\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    205\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python_projects\\Face_Recognition\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:2812\u001B[0m, in \u001B[0;36mbatch_norm\u001B[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[0;32m   2809\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[0;32m   2810\u001B[0m     _verify_batch_size(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize())\n\u001B[1;32m-> 2812\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2813\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2814\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2815\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2816\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrunning_mean\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2817\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2818\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2819\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2820\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2821\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2822\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lr = HP_best[0]\n",
    "warmup_proportion = HP_best[1]\n",
    "weight_decay = HP_best[2]\n",
    "batch_size = HP_best[3]\n",
    "embed_dim = HP_best[4]\n",
    "depth = HP_best[5]\n",
    "num_heads = HP_best[6]\n",
    "mlp_ratio = HP_best[7]\n",
    "drop_rate = HP_best[8]\n",
    "attn_drop_rate = HP_best[9]\n",
    "drop_path_rate = HP_best[10]\n",
    "local_up_to_layer = HP_best[11]\n",
    "locality_strength = HP_best[12]\n",
    "decoder_embed_dim = HP_best[13]\n",
    "decoder_depth = HP_best[14]\n",
    "decoder_num_heads = HP_best[15]\n",
    "filter_size = HP_best[16]\n",
    "num_filters = HP_best[17]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 使用 cuda\n",
    "\n",
    "# 初始化 generator\n",
    "generator = Masked_ConViT_GAN_Generator(\n",
    "    img_size=img_size,\n",
    "    embed_dim=embed_dim,\n",
    "    depth=depth,\n",
    "    num_heads=num_heads,\n",
    "    mlp_ratio=mlp_ratio,\n",
    "    drop_rate=drop_rate,\n",
    "    attn_drop_rate=attn_drop_rate,\n",
    "    drop_path_rate=drop_path_rate,\n",
    "    local_up_to_layer=local_up_to_layer,\n",
    "    locality_strength=locality_strength,\n",
    "    decoder_embed_dim=decoder_embed_dim,\n",
    "    decoder_depth=decoder_depth,\n",
    "    decoder_num_heads=decoder_num_heads\n",
    ").to(device)\n",
    "\n",
    "# 初始化 discriminator\n",
    "discriminator = Masked_ConViT_GAN_Discriminator(\n",
    "    img_size=img_size,\n",
    "    filter_size=filter_size,\n",
    "    num_filters=num_filters\n",
    ").to(device)\n",
    "\n",
    "# 初始化 trainer\n",
    "trainer = Trainer_MCVGAN(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    lr=lr,\n",
    "    warmup_proportion=warmup_proportion,\n",
    "    weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    img_size=img_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_generator()"
   ],
   "id": "a124bcf3b19fea46"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
